[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "one-carat-blog",
    "section": "",
    "text": "Image 01\n\n\nAsian honey bee\n\n\n\n\nImage 02\n\n\nJungle babbler\n\n\n\n\nImage 03\n\n\nBonnet macaque\n\n\n\n\nImage 04\n\n\nIndian peafowl\n\n\n\n\nImage 05\n\n\nNilgiri tahr\n\n\n\n\nImage 06\n\n\nBlue tailed bee eater"
  },
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "",
    "text": "Raw data might not be always in a usable form for any form of analysis or visualization process. The tidyr package aims to help you in reshaping your data in a usable form. In short, it helps you to ‘tidy’ up your data using various tools. In this chapter, we will see how you can use the tidyr package to make your data tidy."
  },
  {
    "objectID": "project5.html#what-is-tidy-data",
    "href": "project5.html#what-is-tidy-data",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n2 What is tidy data?",
    "text": "2 What is tidy data?\nFirst, we need to understand what tidy data looks like. For that let us imagine a scenario where you are a doctor who is trying to find the best treatment for a disease. Now your colleagues have short-listed five different treatment methods and have reported their efficacy values when tested with five different patients. Now you are tasked with finding which of the five treatments is the best against the disease. You open your computer and you find the following data of the experiment.\n\n\n\n\n  \n\n\n\nThis is how often data is stored because it is easy to write it this way. In the first column, you can see the different treatments from one to five. And in the second column, you have the efficacy values of the treatments for patient 1 and it goes on for the other patients. Now, this is a good example of how a dataset should not look like! Surprised? Let us see what makes this dataset ‘dirty’.\nYou can quickly notice that there is no mentioning of what these numerical values mean. Of course, we know that they are efficacy values for the different treatments. But for someone who only has this data as a reference, that person would not have a clue as to what these numbers mean. Also, note that each of the rows contains multiple observation values which is not a feature of tidy data. This kind of data format is called ‘wide data’ which we will talk more about later.\nWith that being said, tidy data will have;\n\nEach of its variables represented in its own column\nEach observation or a case in its own row.\nEach of the rows will contain only a single value.\n\nSo let us see how the ‘tidier’ version of this data would look like.\n\n\n\n\n  \n\n\n\nYou can see each of the columns represent only one type of variable. In the first column, you have the types of treatments, followed by patient IDs and their efficacy values for each treatment. Also, note that each row represents only one observation. So this kind of data format is what we strive to achieve by using the tidyr package and they are called as ‘long data’. So let us begin!"
  },
  {
    "objectID": "project5.html#reshaping-dataset",
    "href": "project5.html#reshaping-dataset",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n3 Reshaping dataset",
    "text": "3 Reshaping dataset\nThere are different sets of commands which you can utilize to reshape your data and make it tidy. Let us each of these commands in action. But first, make sure you have the tidyr package loaded.\n\n# load tidyr package\nlibrary(tidyr)\n\n\n3.1 pivot_longer()\nThe pivot_longer() command converts a ‘wide data’ to a ‘long data’. It does so by converting row names to a new column under a new variable name with its corresponding values moved into another column with another variable name. So let us see how it goes. We will take the earlier mentioned example and will see how to make it tidy. Now you don’t have to be concerned with the codes I have used to make the dummy data. Just have your focus on the pivot_longer() syntax.\n\nlibrary(rmarkdown)\nlibrary(tidyr)\n# making a dummy data\n# using sample function to pick random numbers in a sequence\npatient1 <- c(seq(1,5,1))\npatient2 <- c(seq(6,10,1))\npatient3 <- c(seq(11,15,1))\npatient4 <- c(seq(16,20,1))\npatient5 <- c(seq(21,25,1))\n\n# cbind simple combines the columns of same size\ntreatment_data <- cbind(patient1,patient2,patient3,patient4,patient5) \n\ntrt <- c(\"treatment1\", \"treatment2\",\"treatment3\",\"treatment4\",\"treatment5\")\n\ntrt_data <- cbind(trt, treatment_data)\ntrt_data <- as.data.frame(trt_data) # making it a data frame\n\ntrt_data_tidy <- pivot_longer(trt_data,\n                              c(patient1,patient2,patient3,patient4,patient5), \n                              names_to = \"patient_ID\", values_to = \"efficacy\")\npaged_table(trt_data_tidy)\n\nFurthermore, you don’t have to manually type in the column names as you can use colnames() to call the column names of the dataset. Another way of doing the same is by excluding the first column from the process. By doing so the command will automatically pivot all columns except the excluded ones, so in this way, we don’t need to manually specify the column names. The codes given below will give you the same result as before.\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\npatient1 <- c(seq(1,5,1))\npatient2 <- c(seq(6,10,1))\npatient3 <- c(seq(11,15,1))\npatient4 <- c(seq(16,20,1))\npatient5 <- c(seq(21,25,1))\ntreatment_data <- cbind(patient1,patient2,patient3,patient4,patient5) \ntreatment <- c(\"treatment1\", \"treatment2\",\"treatment3\",\"treatment4\",\"treatment5\")\ntrt_data <- cbind(treatment, treatment_data)\ntrt_data <- as.data.frame(trt_data)\n# using colnames, [-1] is included to exclude the name of first column from the process\ntrt_data_tidy1 <- pivot_longer(trt_data,\n                              colnames(trt_data)[-1], \n                              names_to = \"patient_ID\", values_to = \"efficacy\")\n\n# the same can be done by manually specifying which columns to exclude\n# this can be done by denoting the column name ('treatment' in this case) with '-' sign\ntrt_data_tidy2 <- pivot_longer(trt_data, names_to = \"patient_ID\",\n                               values_to = \"efficacy\", -treatment)\n# checking if both the tidy datasets are one and the same\npaged_table(as.data.frame(trt_data_tidy1 == trt_data_tidy2),\n            options = list(rows.print = 5))\n\n\nThe syntax for pivot_longer() is given below with description\n\npivot_longer(\"data\", c(\"colname1, colname2,.....\"), \n  names_to = \"name of the column where your row names are present\",\n  values_to = \"name of the column where your corresponding row values are present\")\n\nHere is a graphical representation\n\n\n3.2 pivot_wider()\nThe pivot_wider() does the exact opposite of what pivot_longer() does, which is to convert long data into wide data. We will use the previously given dummy data.\n\nlibrary(rmarkdown)\nlibrary(tidyr)\n# making a dummy data\n# using sample function to pick random numbers in a sequence\npatient1 <- c(seq(1,5,1))\npatient2 <- c(seq(6,10,1))\npatient3 <- c(seq(11,15,1))\npatient4 <- c(seq(16,20,1))\npatient5 <- c(seq(21,25,1))\n\n# cbind simple combines the columns of same size\ntreatment_data <- cbind(patient1,patient2,patient3,patient4,patient5) \n\ntrt <- c(\"treatment1\", \"treatment2\",\"treatment3\",\"treatment4\",\"treatment5\")\n\ntrt_data <- cbind(trt, treatment_data)\ntrt_data <- as.data.frame(trt_data) # making it a data frame\n\ntrt_data_tidy <- pivot_longer(trt_data,\n                              c(patient1,patient2,patient3,patient4,patient5), \n                              names_to = \"patient_ID\", values_to = \"efficacy\")\n\n# making the data wide\ntrt_data_wider <- pivot_wider(trt_data_tidy, names_from = \"patient_ID\",\n                              values_from = \"efficacy\")\n\n# paged_Table() for viewing the dataset as a table, \n# you can see that the dataset is same as before\npaged_table(as.data.frame(trt_data_wider))\n\n\n\n  \n\n\n\nThe syntax for pivot_wider() is given below with description\n\npivot_longer(\"data\", \n  names_from = \"name of the column which contains your wide data columns\",\n  values_from = \"name of the column where your corresponding wide data column values are\")\n\nHere is a graphical representation"
  },
  {
    "objectID": "project5.html#splitting-and-uniting-cells",
    "href": "project5.html#splitting-and-uniting-cells",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n4 Splitting and uniting cells",
    "text": "4 Splitting and uniting cells\nThere can be an instance where you want to split or untie cells within your dataset. Let us look at some examples.\n\n4.1 unite()\nIn the data given below, let say we want to unite the century column and the year column together. This can be done using the unite() command. You can view the before and after instances in the tabs below.\n\n\nBefore\nAfter\n\n\n\n\nShow the codelibrary(rmarkdown)\nevent <- c(letters[1:4])\ncentury <- c(rep(19:20, each = 2))\nyear <- c(seq(10,16,2))\ndata <- as.data.frame(cbind(event,century,year))\n\npaged_table(data)\n\n\n\n  \n\n\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nevent <- c(letters[1:4])\ncentury <- c(rep(19:20, each = 2))\nyear <- c(seq(10,16,2))\ndata <- as.data.frame(cbind(event,century,year))\n\n# uniting columns century and year\ndata_new <- unite(data, century, year, col = \"event_year\", sep = \"\")\n# viewing data as a table\npaged_table(data_new)\n\n\n\n  \n\n\n\n\n\n\nThe syntax of unite() is as follows.\n\nunite(\"dataset name\",\n      \"name of first column to unite, name of second column to unite,.......\",\n      col = \"name of the new column to which all the other column will unite together\",\n      sep = \"input any element as a separator between the joining column values\")\n# in this case we are not putting a sep value\n\n\n4.2 separate()\nIn the data given below, let say we want to split the ‘area_perimeter’ column into two separate columns. This can be done using the separate() command. You can view the before and after instances in the tabs below. As always I will be making dummy data to work with.\n\n\nBefore\nAfter\n\n\n\n\nShow the codelibrary(rmarkdown)\n# dummy data\nshapes <- c(letters[1:4])\narea <- c(paste0(10:13, \"m^2\"))\nperimetre <- c(paste0(30:33, \"m\"))\nratio <-as.data.frame(cbind(shapes,area,perimetre))\ndata <- unite(ratio, area, perimetre, col = \"area_perimetre\", sep = \"_\")\n# viewing data as a table\npaged_table(data)\n\n\n\n  \n\n\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nshapes <- c(letters[1:4])\narea <- c(paste0(10:13, \"m^2\"))\nperimetre <- c(paste0(30:33, \"m\"))\nratio <-as.data.frame(cbind(shapes,area,perimetre))\ndata <- unite(ratio, area, perimetre, col = \"area_perimetre\", sep = \"_\")\n\n# separating column values into two separate columns named area and perimeter respectively\ndata_new <- separate(data, area_perimetre, sep = \"_\",\n                     into = c(\"area\", \"perimetre\"))\n# viewing data as a table\npaged_table(data_new)\n\n\n\n  \n\n\n\n\n\n\nThe syntax of separate() is as follows.\n\nseparate(\"data name\",\n         \"column to separate into\",\n         sep = \"the separator element\",\n         into = c(\"col1\", \"col2\", \"........\")) # column names for the separated values\n\n\n4.3 separate_rows()\nSimilar to the above case, you can also separate column values into several rows.\n\n\nBefore\nAfter\n\n\n\n\nShow the codelibrary(rmarkdown)\n# dummy data\nshapes <- c(letters[1:4])\narea <- c(paste0(10:13, \"m^2\"))\nperimetre <- c(paste0(30:33, \"m\"))\nratio <-as.data.frame(cbind(shapes,area,perimetre))\ndata <- unite(ratio, area, perimetre, col = \"area_perimetre\", sep = \"_\")\n# viewing data as a table\npaged_table(data)\n\n\n\n  \n\n\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nshapes <- c(letters[1:4])\narea <- c(paste0(10:13, \"m^2\"))\nperimetre <- c(paste0(30:33, \"m\"))\nratio <-as.data.frame(cbind(shapes,area,perimetre))\ndata <- unite(ratio, area, perimetre, col = \"area_perimetre\", sep = \"_\")\n\n# separating column values into two several rows\ndata_new <- separate_rows(data, area_perimetre, sep = \"_\")\n# viewing data as a table\npaged_table(data_new)\n\n\n\n  \n\n\n\n\n\n\nThe syntax of separate_rows() is as follows.\n\nseparate_rows(\"data name\",\n         \"column to separate\",\n         sep = \"the separator element\")"
  },
  {
    "objectID": "project5.html#expanding-and-completing-dataset",
    "href": "project5.html#expanding-and-completing-dataset",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n5 Expanding and completing dataset",
    "text": "5 Expanding and completing dataset\nYou can expand your data to include all possible combinations of values of variables listed or complete the dataset with NA values for all possible combinations.\n\n5.1 expand()\nUsing the expand() command we can expand our data with missing combinations for the variables we specify.\n\n\nBefore\nAfter\n\n\n\n\nShow the codelibrary(rmarkdown)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\n\n# viewing data as a table\npaged_table(dress_data)\n\n\n\n  \n\n\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\n\n# expanding dataset with brand and dress as variables\ndress_data_expand <- expand(dress_data, brand, dress)\n\n# viewing data as a table\npaged_table(dress_data_expand)\n\n\n\n  \n\n\n\n\n\n\nThe syntax of expand() is as follows.\n\nexpand(\"data name\", \"column names which you want to expand separated by commas\")\n\n\n5.2 complete()\nThe complete() command functions similar to the expand() command, but it also fills in NA values for columns which we didn’t specify, The main reason to use this command would be to convert implicit NA values hidden in the dataset to explicit NA values which are expressed in the dataset. Given below is a comparison between the complete() and expand() commands.\n\n\nexpand()\ncomplete()\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\n\n# expanding dataset with brand and dress as variables\ndress_data_expand <- expand(dress_data, brand, dress)\n\n# viewing data as a table\npaged_table(dress_data_expand)\n\n\n\n  \n\n\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\n\n# completing dataset with brand and dress as variables\n# the variable 'size' will be filled with NAs as we did not specify it\ndress_data_complete <- complete(dress_data,brand,dress)\n\n# viewing data as a table\npaged_table(dress_data_complete)\n\n\n\n  \n\n\n\n\n\n\nThe syntax of complete() is as follows.\n\ncomplete(\"data name\", \"column names which you want to complete separated by commas\")"
  },
  {
    "objectID": "project5.html#handling-nas-or-missing-values",
    "href": "project5.html#handling-nas-or-missing-values",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n6 Handling NAs or missing values",
    "text": "6 Handling NAs or missing values\nMost data collection would often result in possible NA values. The tidyr package allows us to drop or convert NA values. We will reuse the earlier example. Below tabs show before and removing NA values.\n\n6.1 drop_na()\nUse drop_na() to remove NA value containing rows from the dataset.\n\n\nBefore\nAfter\n\n\n\n\nShow the codelibrary(rmarkdown)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\n\ndress_data_complete <- complete(dress_data,brand,dress)\n\n# viewing data as a table\npaged_table(dress_data_complete)\n\n\n\n  \n\n\n\n\n\n\nShow the codelibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\n\ndress_data_complete <- complete(dress_data,brand,dress)\n\n# dropping NA values\n\ndress_data_noNA <- drop_na(dress_data_complete)\n\n# viewing data as a table\npaged_table(dress_data_noNA)\n\n\n\n  \n\n\n\n\n\n\n\n6.2 fill()\nUse fill() to replace NA values by taking values from nearby cells. By default the NA values as replaced by whatever value that is above the cell containing the NA value. This can be changed by specifying the .direction value within fill()\n\nlibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\ndress_data_complete <- complete(dress_data,brand,dress)\n\n# direction 'downup' simultaneously fill both upwards and downwards NA containing cells\ndress_data_fill <- fill(dress_data_complete, size, .direction = \"downup\")\n\n# viewing data as a table\npaged_table(dress_data_fill)\n\n\n\n  \n\n\n\n\n6.3 replace_na()\nUse replace_na() command to replace NA values to whatever value specified.\n\nlibrary(rmarkdown)\nlibrary(tidyr)\n# dummy data\nbrand <- c(letters[1:4])\ndress <- c(\"shirt\", \"pant\", \"jeans\", \"trousers\")\nsize <- c(\"s\", \"m\", \"l\", \"xl\")\ndress_data <- as.data.frame(cbind(brand,dress,size))\ndress_data_complete <- complete(dress_data,brand,dress)\n\n# replace NA to unknown\n# specify the column which have NA inside the list()\n# then equate the value which would replace NAs\ndress_data_zero <- replace_na(dress_data_complete, list(size = \"unknown\"))\n\n# viewing data as a table\npaged_table(dress_data_zero)"
  },
  {
    "objectID": "project5.html#summary",
    "href": "project5.html#summary",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n7 Summary",
    "text": "7 Summary\nSo in this chapter, we learned what is tidy data and how we can make our data into tidy data. Making our data tidy is very important as it helps us to analyse and visualise the data in a very efficient manner. We also learned how to reshape our data, how to split or unite cells, how to complete and expand data and how to handle NA values. Hope this chapter was fruitful for you!"
  },
  {
    "objectID": "project5.html#references",
    "href": "project5.html#references",
    "title": "Chapter 1: Data tidying using tidyr",
    "section": "\n8 References",
    "text": "8 References\n\nHadley Wickham (2021). tidyr: Tidy Messy Data. R package version 1.1.4. https://CRAN.R-project.org/package=tidyr\n\nLast updated on\n\n\n[1] \"2022-05-20 10:19:56 IST\""
  },
  {
    "objectID": "project7.html",
    "href": "project7.html",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "",
    "text": "In the previous chapter we have seen quite a lot of functions from the dplyr package. In this chapter, we will see the rest of the functions where we learn how to handle row names, how to join columns and rows and different set operations in the dplyr package.\n\n# loading necessary packages\nlibrary(dplyr)\n\n\nTidy data does not use row names. So use rownames_to_column() command to convert row names to a new column to the data. The function column_to_rownames() does the exact opposite of rownames_to_column() as it converts a column into rownames but make sure that the column you are converting into rownames does not contain NA values.\n\n# mtcars dataset contains rownames\n# creates new column called car_names which contains row names\nmtcars %>% rownames_to_column(var = \"car_names\")\n\n# returns the original mtcars dataset\nmtcars %>% rownames_to_column(var = \"car_names\") %>%\n  column_to_rownames(var = \"car_names\")"
  },
  {
    "objectID": "project7.html#combine-tablescolumns",
    "href": "project7.html#combine-tablescolumns",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "\n2 Combine tables/columns",
    "text": "2 Combine tables/columns\n\n2.1 bind_cols()\nJoins columns with other columns. Similar function as that of cbind() from base R.\n\ndf1 <- tidytable::data.table(x = letters[1:5], y = c(1:5))\ndf2 <- tidytable::data.table(x = letters[3:7], y = c(6:10))\nbind_cols(df1,df2)\n\n#similar functionality\ncbind(df1,df2)\n\n\n2.2 bind_rows()\nJoins rows with other rows. Similar function as that of rbind() from base R.\n\ndf1 <- tidytable::data.table(x = letters[1:5], y = c(1:5))\ndf2 <- tidytable::data.table(x = letters[3:7], y = c(6:10))\nbind_rows(df1,df2)\n\n#similar functionality\nrbind(df1,df2)\n\nThe functions that are described below have the same functionality as that of bind_cols() but give you control over how the columns are joined."
  },
  {
    "objectID": "project7.html#mutating-joins-and-filtering-joins",
    "href": "project7.html#mutating-joins-and-filtering-joins",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "\n3 Mutating joins and filtering joins",
    "text": "3 Mutating joins and filtering joins\nMutating joins include left_join(), right_join(), inner_join() and full_join() and filtering joins include semi_join() and anti_join().\n\n\nleft_join()\nright_join()\ninner_join()\nfull_join()\nanti_join()\nsemi_join()\n\n\n\nIn the code below, matching variables of df2 are joined with df1. In the final data, you can see that only kevin and sam from df2 are matched with df1, and only those row values are joined with df1. For those variables which didn’t get a match, the row values for those are filled with NA. You can interpret the variables with NA values as; both john and chris are not present in df2.\nIf you are familiar with set theory in mathematics, what we are doing essentially is similar to (df1 \\cap df2) \\cup df1.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\npaged_table(df1 %>% left_join(df2))\n\n\n\n  \n\n\n\n\n\nSimilar to left_join() but here, you will be joining matching values from df1 to df2, the opposite of what we did earlier. As you can see only kevin and sam from the df1 is matched with df2, and only those row values are joined with df2. For the variables which didn’t get a match, the row values for those are filled with NA. You can interpret the variables with NA values as; bob is not present in df1.\nThis function, in the manner used here, is similar to (df1 \\cap df2) \\cup df2.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\npaged_table(df1 %>% right_join(df2))\n\n\n\n  \n\n\n\n\n\nThe function inner_join() compares both df1 and df2 variables and only joins rows with the same variables. Here only kevin and sam are common in both the dataframes so the row values of only those columns are joined and others are omitted.\nThis function is similar to df1 \\cap df2.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\npaged_table(df1 %>% inner_join(df2))\n\n\n\n  \n\n\n\n\n\nThe function full_join() compares both df1 and df2 variables and joins all possible matches while retaining both mistakes in df1 and df2 with NA values.\nThis function is similar to df1 \\cup df2.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\npaged_table(df1 %>% full_join(df2))\n\n\n\n  \n\n\n\n\n\nThis is an example of filtering join. The function anti_join() compares df1 variables to and df2 variables and only outputs those variables of df1 which didn’t get a match with df2.\nThis function, in the manner used here, is similar to df1 \\cap df2^c.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\npaged_table(df1 %>% anti_join(df2))\n\n\n\n  \n\n\n\n\n\nThis is an example of filtering join. The function semi_join() is similar to inner_join() but it only gives variables of df1 which has a match with df2.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\n\npaged_table(df1 %>% semi_join(df2))\n\n\n\n  \n\n\n\n\n\n\nHere is a nice graphical representation of the functions we just described now. Image source.\n\n\n\n\n\n(a) Mutating joins\n\n\n\n\n\n\n(b) Filtering joins\n\n\n\n\nFigure 1: Graphical abstract for joins. Image source: RPubs.com"
  },
  {
    "objectID": "project7.html#additional-commands-for-joins",
    "href": "project7.html#additional-commands-for-joins",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "\n4 Additional commands for joins",
    "text": "4 Additional commands for joins\nAdditionally, you can specify which common columns to match.\n\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\n\n# match with column 'x'\ndf1 %>% left_join(df2, by = \"x\")\n\n       x y  z\n1:  john 1 NA\n2: kevin 2 10\n3: chris 3 NA\n4:   sam 4 11\n5:   sam 5 11\n\ndf3 <- tidytable::data.table(a = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"), y = 1:5)\ndf4 <- tidytable::data.table(b = c(\"kevin\",\"sam\", \"bob\"), z = 10:12)\n\n# matching with column having different names, a and b in this case\ndf3 %>% left_join(df4, by = c(\"a\" = \"b\"))\n\n       a y  z\n1:  john 1 NA\n2: kevin 2 10\n3: chris 3 NA\n4:   sam 4 11\n5:   sam 5 11"
  },
  {
    "objectID": "project7.html#set-operations",
    "href": "project7.html#set-operations",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "\n5 Set operations",
    "text": "5 Set operations\nSimilar to the mutating join functions that we had seen, there are different functions related to set theory operations.\n\n5.1 intersect()\nOutputs common rows in the dataset.\n\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"))\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"))\n\nintersect(df1, df2)\n\n       x\n1: kevin\n2:   sam\n\n\n\n5.2 setdiff()\nOutputs rows in first data frame but not in second data frame.\n\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"))\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"))\n\nsetdiff(df1, df2)\n\n       x\n1:  john\n2: chris\n\n\n\n5.3 union()\nOutputs all the rows in both dataframes\n\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"))\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"))\n\nunion(df1, df2)\n\n       x\n1:  john\n2: kevin\n3: chris\n4:   sam\n5:   bob\n\n\n\n5.4 setequal()\nChecks whether two datasets have same number of rows.\n\nlibrary(dplyr)\n\ndf1 <- tidytable::data.table(x = c(\"john\",\"kevin\",\"chris\",\"sam\",\"sam\"))\ndf2 <- tidytable::data.table(x = c(\"kevin\",\"sam\", \"bob\"))\n\nsetequal(df1, df2)\n\n[1] FALSE"
  },
  {
    "objectID": "project7.html#summary",
    "href": "project7.html#summary",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "\n6 Summary",
    "text": "6 Summary\nIn this chapter, we have seen;\n\n\nHow to handle row names\nHow to combine columns and rows\nWhat are mutating and filtering joins and various set operations\n\n\nThus to conclude this chapter, we have now learned almost all functions in the dplyr package and have seen how to manipulate data efficiently. With the knowledge of the pipe operator that we have seen in chapter 1, we are now equipped to write codes compactly and more clearly. I hope this chapter was useful for you and I will see you next time."
  },
  {
    "objectID": "project7.html#references",
    "href": "project7.html#references",
    "title": "Chapter 3: Data manipulation using dplyr (part 2)",
    "section": "\n7 References",
    "text": "7 References\n\nHadley Wickham, Romain François, Lionel Henry and Kirill Müller (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. https://CRAN.R-project.org/package=dplyr. Here is the link to the cheat sheet explaining each and every function in dplyr.\n\nLast updated on\n\n\n[1] \"2022-05-20 10:19:35 IST\""
  },
  {
    "objectID": "project6.html",
    "href": "project6.html",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "",
    "text": "The dplyr package is a grammar of data manipulation just like how ggplot2 is the grammar of data visualization. It helps us to apply a wide variety of functions such as;\n\nSummarising the dataset\nApplying selections and orderings as a function of a variable\nCreating new variables as a function of existing variables\n\nWe will see in-depth how to manipulate our data like a boss!"
  },
  {
    "objectID": "project6.html#the-pipe-operator",
    "href": "project6.html#the-pipe-operator",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n2 The pipe operator %>%",
    "text": "2 The pipe operator %>%\nPerhaps the most amazing thing in making codes short and efficient is the pipe operator which is originally from the magrittr package which is made available for the dplyr package. The pipe operator helps you skip the intermediate steps of saving an object before you can use them in command. It does so by ‘piping’ together results from the first object to the function ahead of the pipe operator. The command x %>% y %>% z can be read as ‘take the result of x and use it with function y and take that result and use it with function z’. This is the gist of what the pipe operator does. Allow me to demonstrate.\n\nlibrary(ggplot2)\n\n# dummy data\na <- c(sample(1:100, size = 50))\nb <- c(sample(1:100, size = 50))\ndata <- as.data.frame(cbind(a,b))\n\n# without %>%\ndata <- mutate(data, ab = a*b, twice_a = 2*a)\ndata_new <- filter(data, ab < 300, twice_a < 200)\nggplot(data_new, aes(ab, twice_a)) + geom_point()\n\n# with %>%\ndata %>% mutate(ab = a*b, twice_a = 2*a) %>% \n  filter(ab < 300, twice_a < 200) %>%\n  ggplot(aes(ab, twice_a)) + geom_point()\n\nAs you can see, with pipe operator %>%, we did not have to save any objects in the intermediate steps and also it improved the overall clarity of the code. I have used a few commands from the dplyr package in the example given above. So without further ado let us delve into the dplyr package. For this chapter, I will be using the penguin dataset from the popular {palmerpenguin} package as an example.\n\n# install palmerpenguins package\ninstall.packages(\"palmerpenguins\")\nlibrary(dplyr)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "project6.html#grouping-the-data",
    "href": "project6.html#grouping-the-data",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n3 Grouping the data",
    "text": "3 Grouping the data\n\n3.1 group_by()\nThe command group_by() allows us to group the data via existing variables. It allows for a ‘split-apply-combine’ way of getting output. First, it will split the data or group the data with the levels in the variable, then apply the function of our choice and then finally combine the results to give us a tabular output. On its own the command doesn’t do anything, we use it in conjunction with other commands to get results based on the grouping we specify. The command ungroup() is used to ungroup the data."
  },
  {
    "objectID": "project6.html#summarising-the-data",
    "href": "project6.html#summarising-the-data",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n4 Summarising the data",
    "text": "4 Summarising the data\n\n4.1 summarise()\nThe summarise() command allows you to get the summary statistics of a variable or a column in the dataset. The result is given as tabular data. Many types of summary statistics can be obtained using the summarise() function. Some of them are given below. To calculate average values it is necessary to drop NA values from the dataset. Use drop_na() command from the tidyr package. The comments denote what each summary statistic is.\n\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(palmerpenguins)\nlibrary(rmarkdown)\n\nsummary_data <- penguins %>% drop_na() %>%\n  group_by(species) %>% # we are grouping/splitting the data according to species\n  summarise(avg_mass = mean(body_mass_g), # mean mass\n            median_mass = median(body_mass_g), # median mass\n            max_mass = max(body_mass_g), # max value of mass, can also use min()\n            standard_deviation_bill_length = sd(bill_length_mm), # standard deviation of bill_length\n            sum_mass = sum(flipper_length_mm), # sum\n            distinct_years = n_distinct(year), # distinct values in column year\n            no_of_non_NAs = sum(!is.na(year)), # gives no of non NAs, \n            length_rows = n(), # length of the rows\n            iqr_mass = IQR(body_mass_g), # inter quartile range of mass\n            median_absolute_deviation_mass = mad(body_mass_g), # median absolute deviation of mass\n            variance_mass = var(body_mass_g)) # variance\n# viewing summary as a table\npaged_table(summary_data)\n\n\n\n  \n\n\n\nThe number of non NA values will be the same as that of n() result as we have used drop_na()command in the beginning.\nThe base function summary() in R also gives the whole summary statistics of a dataset.\n\nlibrary(palmerpenguins)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\n\n4.2 when to use group_by()\nIt can be confusing to decide when to use the group_by() function. In short, you should use it whenever you want any function to act separately on different groups present in the dataset. Here is a graphical representation of how the summarise() function is used to calculate the mean values of a dataset. When used with group_by() it calculates mean values for the respective groups in the data, but when group_by() is not used, it will calculate the mean value of the entire dataset irrespective of the different groups present and outputs a single column.\n\n\n\n\n\n\n4.3 count()\nThe count() command is used to count the number of rows of a variable. Has the same function as that of n()\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\ncount <- penguins %>% group_by(species) %>%\n  count(island)\n# viewing count as a table\npaged_table(count)"
  },
  {
    "objectID": "project6.html#manipulating-cases-or-observations",
    "href": "project6.html#manipulating-cases-or-observations",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n5 Manipulating cases or observations",
    "text": "5 Manipulating cases or observations\nThe following functions affect rows to give a subset of rows in a new table as output.\n\n5.1 filter()\nUse filter() to filter rows corresponding to a given logical criteria\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% filter(body_mass_g < 3000))\n\n\n\n  \n\n\n\n\n5.2 distinct()\nUse distinct() to remove rows with duplicate or same values.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% group_by(species) %>% distinct(body_mass_g))\n\n\n\n  \n\n\n\n\n5.3 slice()\nUse slice() to select rows by position.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% slice(1:5)) # slice from first row to fifth row\n\n\n\n  \n\n\n\n\n5.4 slice_sample()\nUse slice_sample() to randomly select rows from the dataset. Instead of (n = ) you can also provide the proportion value (between 0 and 1) using (prop = ). For e.g. for a dataset with 10 rows, giving (prop = 0.5) will randomly sample 5 rows. Other related functions include;\n\n\npreserve : Values include TRUE to preserve grouping in a grouped dataset and FALSE to not preserve grouping while sampling.\n\nweight_by : Gives priority to a particular variable during sampling. An example is given below.\n\nreplace : Values include TRUE if you want sampling with replacement which can result in duplicate values, FALSE if you want sampling without replacement.\n\n\n\n(n = 4)\nweight_by\n\n\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# samples 4 rows randomly\npaged_table(penguins %>% slice_sample(n = 4))\n\n\n\n  \n\n\n\n\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# sampling will favour rows with higher values of 'body_mass_g'\npaged_table(penguins %>% drop_na() %>% slice_sample(n = 4, weight_by = body_mass_g))\n\n\n\n  \n\n\n\n\n\n\n\n5.5 slice_min() and slice_max()\nUse slice_min() to extract rows containing least values and use slice_max() to extract rows with greatest values. The function with_ties = FALSE is included to avoid tie values.\n\n\nslice_min()\nslice_max()\n\n\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% slice_min(body_mass_g, n = 4, with_ties = FALSE))\n\n\n\n  \n\n\n\n\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% slice_max(body_mass_g, n = 4,with_ties = FALSE))\n\n\n\n  \n\n\n\n\n\n\n\n5.6 slice_head() and slice_tail()\nUse slice_head() to extract first set of rows and use slice_tail() to extract last set of rows.\n\n\nslice_head()\nslice_tail()\n\n\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% slice_head(n = 4))\n\n\n\n  \n\n\n\n\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% slice_tail(n = 4))\n\n\n\n  \n\n\n\n\n\n\n\n5.7 arrange()\nUse arrange() to arrange rows in a particular order.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# arranging rows in descending order of bill length\n# by default it arranges data by ascending order when no specifications are given\npaged_table(penguins %>% arrange(desc(bill_length_mm)))\n\n\n\n  \n\n\n\n\n5.8 add_row()\nUse add_row() to add rows to the dataset.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\n\nName <- c(\"a\", \"b\")\nAge <- c(12,13)\npaged_table(data.frame(Name, Age) %>% add_row(Name = \"c\", Age = 15))"
  },
  {
    "objectID": "project6.html#manipulating-variables-or-columns",
    "href": "project6.html#manipulating-variables-or-columns",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n6 Manipulating variables or columns",
    "text": "6 Manipulating variables or columns\nThe following functions affect columns to give a subset of columns in a new table as output.\n\n6.1 pull()\nUse pull() to extract columns as a vector, by name or index. Only the first 10 results are shown for easy viewing.\n\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npenguins %>% pull(body_mass_g)\n\n\n6.2 select()\nUse select() to extract columns as tables, by name or index.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% select(species, body_mass_g))\n\n\n\n  \n\n\n\n\n6.3 relocate()\nUse relocate() to move columns to new position. Results are not shown as these are trivial results.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# relocates 'species' column to last position\npaged_table(penguins %>% relocate(species, .after = last_col()))\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# relocates 'species' column before column 'year' and renames the column as 'penguins'\npaged_table(penguins %>% relocate(penguins = species, .before = year))\n\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# you can also relocate columns based on their class\n# relocates all columns with 'character' class to last position\npaged_table(penguins %>% relocate(where(is.character), .after = last_col()))\n\n\n6.4 rename()\nUse rename() function to rename column names in the dataset.\n\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# renames the column sex to gender\npenguins %>% rename(gender = sex)\n\n\n6.5 mutate()\nUse mutate() function to create new columns or variables.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% drop_na() %>% \n  group_by(species) %>%\n  mutate(mean_mass = mean(body_mass_g)))\n\n\n\n  \n\n\n\n\n6.6 transmute()\nDoes the same function as mutate() but in the process will drop any other columns and give you a table with only the newly created columns.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% drop_na() %>% \n  group_by(species) %>%\n  transmute(mean_mass = mean(body_mass_g)))\n\n\n\n  \n\n\n\n\n6.7 across()\nUse across() to summarise or mutate columns in the same way. First example shows across() used with summarise() function.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# summarise across columns body mass, bill length and bill depth\n# and calculate the mean values\n# since we are calculating mean values,\n# NAs are dropped using 'drop_na() function from 'tidyr' package\n\npaged_table(penguins %>% drop_na() %>%\n  group_by(species) %>%\n  summarise(across(c(body_mass_g, bill_length_mm, bill_depth_mm), mean)))\n\n\n\n  \n\n\n\nSecond example showing across() used with mutate() function. We can efficiently create new columns using mutate() and across() together. Suppose we want to multiply all numerical values in a dataset with 2 and create new columns of those values. This can be done using the code below.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# define the function\ntwo_times <- function(x) {\n  2*x\n} \n\n# .name will rename the new columns with 'twice` prefix combined with existing col names\npaged_table(penguins %>% group_by(species) %>%\n  mutate(across(where(is.numeric), two_times, .names = \"two_times_{col}\")))\n\n\n\n  \n\n\n\nThe same code when used just with mutate() function will look like this\n\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n# define the function\ntwo_times <- function(x) {\n  2*x\n}\n\n# using only 'mutate()' function\npenguins %>% group_by(species) %>%\n  mutate(twice_bill_lenght = two_times(bill_length_mm),\n         twice_body_mass = two_times(body_mass_g),\n         .....)\n\nSo in this code, I will have to manually type all the col names and apply the operation individually which is too much of a hassle. Now we can better appreciate how efficient it is in using mutate() and across() functions together.\n\n6.8 c_across()\nThe function c_across() is similar to the earlier mentioned across() function. But instead of doing a column-wise function, it applies function across columns in a row-wise manner. Now, most functions in R by default computes across columns, so to specify row-wise computation, we have to explicitly use the function rowwise() in conjunction with other functions. In the example below we will sum both bill and flipper lengths of the penguins in the penguins dataset and create a new column called ‘sum_of_lengths’.\n\nlibrary(rmarkdown)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npaged_table(penguins %>% drop_na() %>%\n  group_by(species) %>%\n  rowwise() %>%\n  transmute(sum_of_length = sum(c_across(c(bill_length_mm,flipper_length_mm)))))"
  },
  {
    "objectID": "project6.html#summary",
    "href": "project6.html#summary",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n7 Summary",
    "text": "7 Summary\nThe dplyr package is the grammar of the data manipulation in R. It features well-made functions to help us summarise the data, group data by variables and manipulate columns and rows in the dataset. In this chapter, we learned in detail the different functions that help us manipulate data efficiently and have seen case examples also. In the next chapter, we will see the remaining set of functions in the dplyr package."
  },
  {
    "objectID": "project6.html#references",
    "href": "project6.html#references",
    "title": "Chapter 2: Data manipulation using dplyr (part 1)",
    "section": "\n8 References",
    "text": "8 References\n\nHadley Wickham, Romain François, Lionel Henry and Kirill Müller (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. https://CRAN.R-project.org/package=dplyr Here is the link to the cheat sheet explaining each function in dplyr.\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/\nHadley Wickham (2021). tidyr: Tidy Messy Data. R package version 1.1.4. https://CRAN.R-project.org/package=tidyr\n\nLast updated on\n\n\n[1] \"2022-05-20 10:22:53 IST\""
  },
  {
    "objectID": "project1.html",
    "href": "project1.html",
    "title": "Chapter 1: Data visualization using ggplot2",
    "section": "",
    "text": "In this chapter we will be plotting different types of graphs using a package called ggplot2 in R. The ggplot2 package is based on ‘grammar of graphics plot’ which provides a systematic way of doing data visualizations in R. With a few lines of code you can plot a simple graph and by adding more layers onto it you can create complex yet elegant data visualizations.\nA ggplot2 graph is made up of three components.\n\n\nData: Data of your choice that you want to visually summarise.\n\nGeometry or geoms: Geometry dictates the type of graph that you want to plot and this information is conveyed to ggplot2 through the geom() command code. For e.g. using the geom_boxplot() command, you can plot a box plot with your data. Likewise, there are many types of geometry that you can plot using the ggplot2 package.\n\nAesthetic mappings: Aesthetics define the different kinds of information that you want to include in the plot. One fo the most important aesthetic is in choosing which data values to plot on the x-axis and the y-axis. Another example is changing the colour of the data points, which can be used to differentiate two different categories in the data. The use of aesthetics depends on the geometry that you are using. We use the command aes() for adding different types of aesthetics to the plot. We will learn more about aes() in Chapter 2.\n\nThis tutorial is primarily focused on students who are beginners in R programming and wants to quickly plot their data without much of a hassle. So without further ado let’s plot some graphs!"
  },
  {
    "objectID": "project1.html#setting-up-the-prerequisites",
    "href": "project1.html#setting-up-the-prerequisites",
    "title": "Chapter 1: Data visualization using ggplot2",
    "section": "\n2 Setting up the prerequisites",
    "text": "2 Setting up the prerequisites\nFirst, we need to install the ggplot2 package in R as it does not come in the standard distribution of R.\n\nTo install packages in R we use the command install.packages() and to load packages we use the command library(). Therefore to install and load ggplot2 package we use the following lines of command.\n\n\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nAll right we have the ggplot2 package loaded, now we just need some data to plot. Most R programming tutorials use the iris dataset as an example. But this tutorial won’t be like most tutorials. So let me introduce you to some lovely penguins from Palmer Station in Antarctica!\nFor this tutorial, we will be installing the palmerpenguins package which showcases body measurements taken from three different species of penguins from Antarctica. This package was made possible by the efforts of Dr. Allison Horst. The penguin data was collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER.\n\nInstall the palmerpenguins package and load it in R.\n\n\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\n\nNow there are two datasets in this package. We will be using the penguins dataset which is a simplified version of the raw data present in the package.\n\nUse the command head() to display the first few values of penguins dataset to see how it looks like\n\n\nlibrary(palmerpenguins)\nknitr::kable(head(penguins))\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\nWe can see that are 8 columns in the dataset representing different values. Now let us try plotting some graphs with this data.\n\n2.1 Bar graph\nSo we will try to plot a simple bar graph first. Bar graphs are used to represent categorical data where the height of the rectangular bar represents the value for that category. We will plot a bargraph representing frequency data for all three species of penguins.\n\nWe will be using the geom_bar() command to plot the bar graph. Let us also use the command theme_bw() for a nice looking theme.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = species, fill = species)) + \n  xlab(\"Species\") + ylab(\"Frequency\") + \n  ggtitle(\"Frequency of individuals for each species\") + \n  geom_bar() + theme_bw()\n\n\n\n\n\n2.2 Histogram\nHistograms are similar to bar graphs visually. But histograms are used to represent continuous data. Also the all the rectangular bars will have the same bin size or width.\n\nWe can plot a histogram using the command geom_histogram().\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = body_mass_g, fill = species)) + \n  xlab(\"Body Mass (g)\") + ylab(\"Frequency\") + \n  ggtitle(\"Frequency of individuals for respective body mass\") + \n  geom_histogram(bins = 25) + theme_bw()\n\nWarning: Removed 2 rows containing non-finite values (stat_bin).\n\n\n\n\n\nThe warning message indicates that for two rows in the dataset, they have NA values or that they did not have any values present. This is true for real-life cases, as during data collection sometimes you will be unable to collect data due to various reasons. So this is perfectly fine.\n\n2.3 Line graph\nLine graph simply joins together data points to show overall distribution.\n\nUse the command geom_line() for plotting a line graph.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = bill_length_mm, \n                            y = bill_depth_mm, colour = species)) + \n  xlab(\"Bill length (mm)\") + ylab(\"Bill depth (mm)\") + \n  ggtitle(\"Bill length vs Bill depth\") + geom_line() + theme_bw()\n\n\n\n\n\n2.4 Scatter plot\nThe scatter plot simply denotes the data points in the dataset.\n\nUse the command geom_point() to plot a scatter plot.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm, \n                            shape = species, colour = species)) + \n  xlab(\"Body mass (g)\") + ylab(\"Flipper length (mm)\") + \n  ggtitle(\"Body mass vs Filpper length\") + geom_point(size = 2) + theme_bw()\n\n\n\n\n\n2.5 Density Plot\nDensity plots are similar to histograms but show it shows the overall distribution of the data in a finer way. This way we will get a bell-shaped curve if our data follows a normal distribution.\n\nUse the command geom_density() to a density plot.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = body_mass_g, fill = species)) + \n  xlab(\"Body Mass (g)\") + ylab(\"Density\") + ggtitle(\"Body mass distribution\") + \n  geom_density() + theme_bw()\n\n\n\n\nSince we plotted for all three species the graph looks clustered. Let us try plotting the same graph for only gentoo penguins. We will use the dplyr package to filter() data for gentoo penguins alone. The dplyr package comes in-built with R so just load the dplyr package using the command library().\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\nlibrary(dplyr)\n\npenguins_gentoo <- penguins %>% filter(species == \"Gentoo\")\n\nggplot(data = penguins_gentoo, aes(x = body_mass_g)) + \n  xlab(\"Body Mass of Gentoo penguins (g)\") + ylab(\"Density\") + \n  ggtitle(\"Body mass distribution of Gentoo penguins\") + \n  geom_density(fill = \"red\") + theme_bw()\n\n\n\n\n\n2.6 Dot-plot\nDot-plot is similar to a density plot but it shows discretely each data point in the distribution.\n\nUse the command geom_dotplot() to plot a dot-plot.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = species, y = body_mass_g, fill = species)) + \n  xlab(\"Species\") + ylab(\"Body mass (g)\") + \n  ggtitle(\"Body mass in three diferent species of penguins\") + \n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", binwidth = 100) + theme_bw()\n\n\n\n\n\n2.7 Rug-plot\nRug-plot is a simple way to visualize the distribution of data along the axis lines. It is often used in conjunction with other graphical representations.\n\nUse the command geom_rug() to plot a rug-plot.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\nlibrary(dplyr)\n\npenguins_gentoo <- penguins %>% filter(species == \"Gentoo\")\n\nggplot(data = penguins_gentoo, aes(x = body_mass_g, y = flipper_length_mm)) + \n  xlab(\"Body Mass of Gentoo penguins (g)\") + ylab(\"Density\") + \n  ggtitle(\"Body mass distribution of Gentoo penguins\") + \n  geom_point(colour = \"darkred\") + geom_rug() + theme_bw()\n\n\n\n\n\n2.8 Box plot\nBox-plot is one of the better ways of showing data via quartiles. You can learn more about box plots here.\n\nUse the command geom_boxplot() to plot a box-plot.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = species, y = body_mass_g, colour = species)) + \n  xlab(\"Species\") + ylab(\"Body mass (g)\") + \n  ggtitle(\"Body mass in three diferent species of penguins\") + geom_boxplot() + \n  theme_bw()\n\n\n\n\n\n2.9 Violin plot\nViolin plot can be considered as the best of both a box-plot and a density plot. It shows the quartile values, like in a box-plot and also shows the distribution of the data, like in a density plot.\n\nUse the command geom_violin() in conjunction with geom_boxplot() to plot a violin plot.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = species, y = body_mass_g, fill = species)) + \n  xlab(\"Species\") + ylab(\"Body mass (g)\") + \n  ggtitle(\"Body mass in three diferent species of penguins\") + \n  geom_violin(aes(colour = species), trim = TRUE) + geom_boxplot(width = 0.2) +\n  theme_bw()"
  },
  {
    "objectID": "project1.html#saving-your-ggplot2-graphs",
    "href": "project1.html#saving-your-ggplot2-graphs",
    "title": "Chapter 1: Data visualization using ggplot2",
    "section": "\n3 Saving your ggplot2 graphs",
    "text": "3 Saving your ggplot2 graphs\n\nUse the command ggsave() to save the graph locally. In the code below, ‘my_graph’ is the ggplot element containing your graph. The plot will be saved in your working directory.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nmy_graph <- ggplot(data = penguins, aes(x = species, y = body_mass_g,\n                                    fill = species)) + \n  xlab(\"Species\") + ylab(\"Body mass (g)\") + \n  ggtitle(\"Body mass in three diferent species of penguins\") + \n  geom_violin(aes(colour = species), trim = TRUE) + \n  geom_boxplot(width = 0.2) +\n  theme_bw()\n\n#to save the plot\nggsave(my_graph, filename = \"your_graph_name.png\", width = 20, height = 20,\n       units = \"cm\")"
  },
  {
    "objectID": "project1.html#summary",
    "href": "project1.html#summary",
    "title": "Chapter 1: Data visualization using ggplot2",
    "section": "\n4 Summary",
    "text": "4 Summary\nI hope this tutorial helped you to get familiarized with the ggplot2 commands. There are many more different types of graphs that you can plot using ggplot2. The tutorial only showed some of the commonly used ones. The best way to learn R is through actually doing it yourself. Try to recreate the examples given in this tutorial by yourself and then try what you learned with the different datasets available in R. Have a good day!"
  },
  {
    "objectID": "project1.html#references",
    "href": "project1.html#references",
    "title": "Chapter 1: Data visualization using ggplot2",
    "section": "\n5 References",
    "text": "5 References\n\nH. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016. Read more about ggplot2 here. You can also look at the cheat sheet for all the syntax used in ggplot2. Also check this out.\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.\n\nLast updated on\n\n\n[1] \"2022-05-20 10:21:31 IST\""
  }
]