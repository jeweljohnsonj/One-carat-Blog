{
  "hash": "9db451a2f81b84d2f06a8fc6c3fd02b2",
  "result": {
    "markdown": "---\ntitle: \"Intermediate statistical modelling in R\"\ndescription: \"Learn about interaction terms, total and partial change, R-squared values, bootstrapping and collinearity\"\ndate: \"08/11/2022\"\ndate-modified: last-modified\nformat:\n  html:\n    css:\n      - https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css\nimage: images/stat_model_2.png\ncategories: [statistical modelling]\nfilters:\n   - social-share\nshare:\n  permalink: \"https://one-carat-blog.netlify.app/tutorials/stat_model/inter_stat_model.html\"\n  description: \"Intermediate statistical modelling in R\"\n  twitter: true\n  facebook: true\n  reddit: true\n  stumble: true\n  tumblr: true\n  linkedin: true\n  email: true\n---\n\n```{ojs}\n//| output: false\n//| echo: false\nrequire(\"https://cdn.jsdelivr.net/npm/juxtaposejs@1.1.6/build/js/juxtapose.min.js\")\n  .catch(() => null)\n```\n\n\n:::{.callout-note}\n## TL;DR\n\nIn this article you will learn;\n\n1. Interpreting effect size when the response variable is categorical\n\n2. Plotting model output using the `fmodel()` function from the `{statisticalModeling}` package\n\n3. Interaction terms\n\n4. Polynomial regression\n\n5. Total change and partial change\n\n6. Interpreting the R-squared value in terms of model output and residuals\n\n7. Bootstrapping technique to measure the precision of model statistics\n\n8. Scales and transformation\n    * Log transformation\n    * Rank transformation\n    \n9. Collinearity\n\n:::\n\n## Prologue\n\nThis tutorial serves as a sequel to the tutorial post: [Introduction to statistical modelling in R](https://one-carat-blog.netlify.app/tutorials/stat_model/intro_stat_model.html). In this tutorial, you will gain knowledge in intermediate statistical modelling using R. You will learn more about effect sizes, interaction terms, total change and partial change, bootstrapping and collinearity.\n\n## Making life easier\n\nPlease install and load the necessary packages and datasets which are listed below for a seamless tutorial session. (Not required but can be very helpful if you are following this tutorial code by code)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries used in this tutorial\ninstall.packages('NHANES')\ninstall.packages('devtools')\ndevtools::install_github(\"dtkaplan/statisticalModeling\")\ninstall.packages('mosaicData')\ninstall.packages('mosaicModel')\ninstall.packages('Stat2Data')\ninstall.packages('cherryblossom')\ninstall.packages(\"tidyverse\")\ninstall.packages(\"mosaic\")\n\n# Loading the libraries\ntutorial_packages <- c(\"cherryblossom\", \"mosaicData\", \"NHANES\",\n                 \"Stat2Data\", \"tidyverse\", \"mosaic\", \"mosaicModel\", \"statisticalModeling\")\n\nlapply(tutorial_packages, library, character.only = TRUE)\n\n# Datasets used in this tutorial\ndata(\"NHANES\") # From NHANES\ndata(\"SwimRecords\") # From mosaicData\ndata(\"Tadpoles\") # From mosaicModel\ndata(\"HorsePrices\") # From Stat2Data\ndata(\"run17\") # From cherryblossom\ndata(\"Oil_history\") # From statisticalModeling\ndata(\"SAT\") # From mosaicData\n```\n:::\n\n\n## Effect size when response variable is categorical\n\nIn the last tutorial, we learned how to calculate the effect size for an explanatory variable. To recall, we learned that;\n\n| Exploratory variable type | Effect size | Error |\n|---|---|---|\n| Numerical | Rate of change (slope) | Mean of the square of the prediction error (m.s.e) |\n| Categorical | Difference (change) | Likelihood value |\n\nSo depending on the nature of the exploratory variable, the nature of the effect size will also change. For a numerical exploratory variable, the effect size is represented as the slope of the line, which represents the rate of change. For a categorical response variable, the effect size is represented as the difference in model output values, when the variable changes from one category to the other.\n\nWe also learned that, for a categorical response variable, it's helpful to represent the model output as probability values rather than class values. Therefore, for calculating errors, if we have a numerical response variable then the error metric is the mean of the square of the prediction error and for a categorical response variable, the error would be the likelihood value. We saw in detail how to find each of them.\n\nBut what we did not calculate back then was the effect size, if we had a categorical response variable. So what intuition would effect size make here for this case? Let us find out.\n\nWe will be using the `NHANES` dataset from the `{NHANES}` package in R, the same one we saw last time while learning to interpret the recursive partitioning model plots. Back then, our exploratory analysis found that depression is having a strong association with the interest in doing things on a given day. Let us build that model using the `rpart()` function. Here the model will have `Depressed` as the response variable and `LittleInterest` as the explanatory variable. Please note that here both the variables are categorical. \n\nThe levels for `Depressed` are; “None” = No sign of depression, “Several” = Individual was depressed for less than half of the survey period days, and “Most” = Individual was depressed more than half of the days. \n\nThe levels for `LittleInterest` are also similar to that of `Depressed`; \"None\", \"Several\" and \"Most\", and are analogous to levels of `Depressed`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(NHANES)) install.packages('NHANES')\nif (!require(rpart)) install.packages('rpart')\nif (!require(devtools)) install.packages('devtools')\nif (!require(statisticalModeling)) devtools::install_github(\"dtkaplan/statisticalModeling\")\n\n# Loading libraries\nlibrary(NHANES)\nlibrary(rpart)\nlibrary(statisticalModeling)\n\n# Building the recursive partitioning model\nmodel_rpart <- rpart(Depressed ~ LittleInterest, data = NHANES)\n\n# Calculating the effect size\neffect_size_rpart <- effect_size(model_rpart, ~ LittleInterest)\n\n# Printing the effect size\neffect_size_rpart\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"change.None\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"change.Several\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"change.Most\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"LittleInterest\"],\"name\":[4],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"to:LittleInterest\"],\"name\":[5],\"type\":[\"fct\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"-0.4466272\",\"2\":\"0.3628062\",\"3\":\"0.08382102\",\"4\":\"None\",\"5\":\"Several\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAll right, we got the effect size values and they are given in two columns; 'change.None' and 'change.Several'. Since our explanatory variable is categorical, effect size values with a categorical response variable give the change in probability values. Here, notice that the effect size is calculated as the difference when the response variable is changing its category from 'None' to 'Several'. That difference is the probability difference from the base value, which is zero. \n\nTo make more sense, imagine we get an effect size value of zero, in both the columns, in the above case. This means that when the level of little interest changes from 'None' to 'Several', there is no increase or decrease in the probability of depression is 'None' or 'Several'. This means, that if a person is having no depression, changing little interest from 'None' to 'Several' will not evoke a change in that person's depressed state. Thus zero is taken as the base value.\n\nNow let us look at the actual effect size values we got. As the level of little interest is changing from 'None' to 'Several', we get a probability difference of -0.4466272 = ~ 0.45 for depression is 'None'. This means that there is a reduction of 45% in the base value of probability. In other words, the person is 45% less likely to have depression set to 'None'. Likewise, in the same notion, the person is 36% more likely to have a depressed state of 'Several', when little interest changes from 'None' to 'Several'. I hope this was clear to you.\n\nNow, let us look at the case when, again, our response variable is categorical but this time, our explanatory variable is numerical.\n\nLet us make another recursive partitioning model. We will have `SmokeNow` as the response variable and our explanatory variable will be `BMI`, which denotes the body mass index of the participants. The `SmokeNow` variable denotes smoking habit and has two levels; \"Yes\" = smoked 100 or more cigarettes in their lifetime., and \"No\" = did not smoke 100 or more cigarettes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(NHANES)) install.packages('NHANES')\nif (!require(rpart)) install.packages('rpart')\nif (!require(devtools)) install.packages('devtools')\nif (!require(statisticalModeling)) devtools::install_github(\"dtkaplan/statisticalModeling\")\n\n# Loading libraries\nlibrary(NHANES)\nlibrary(rpart)\nlibrary(statisticalModeling)\n\n# Building the recursive partitioning model\nmodel_rpart <- rpart(SmokeNow ~ BMI, data = NHANES)\n\n# Calculating the effect size\neffect_size_rpart <- effect_size(model_rpart, ~ BMI)\n\n# Printing the effect size\neffect_size_rpart\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope.No\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"slope.Yes\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BMI\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:BMI\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"0\",\"3\":\"25.98\",\"4\":\"33.35658\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nLooks like we got the effect size values as zero. Going by our previous notion, this means that when BMI is changed from 26 to 33, there is no change in smoking habit. Does this mean that BMI has no relationship with the smoking habit? \n\nBefore we conclude, let us try a different model architecture. We learned about logistic modelling last time. Let us build a model using it for the same question. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(NHANES)) install.packages('NHANES')\nif (!require(devtools)) install.packages('devtools')\nif (!require(statisticalModeling)) devtools::install_github(\"dtkaplan/statisticalModeling\")\n\n# Loading libraries\nlibrary(NHANES)\nlibrary(statisticalModeling)\n\n# Building the logistic model\nmodel_logistic <- glm(SmokeNow == \"No\" ~ BMI, data = NHANES, family = \"binomial\")\n\n# Calculating the effect size\neffect_size_logistic <- effect_size(model_logistic, ~ BMI)\n\n# Printing the effect size\neffect_size_logistic\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BMI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:BMI\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.008784786\",\"2\":\"25.98\",\"3\":\"33.35658\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWe got a very small effect size value but a non-zero value. Let us try plotting both models. We will use the `fmodel()` function in the `{statisticalModeling}` package to easily plot the model. Use the slider to view between the plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plotting both recursive partitioning model\nfmodel(model_rpart) + ggplot2::theme_bw() + \n  ggplot2::labs(title = \"SmokeNow ~ Age (recursive partitioning model)\")\n\n# Plotting both logistic model\nfmodel(model_logistic) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"SmokeNow ~ Age (logistic model)\")\n```\n:::\n\n\n::: {.juxtapose data-startingposition=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plotting both recursive partitioning model\nfmodel(model_rpart) + ggplot2::theme_bw() + \n  ggplot2::labs(title = \"SmokeNow ~ Age (recursive partitioning model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plotting both logistic model\nfmodel(model_logistic) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"SmokeNow ~ Age (logistic model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n:::\n\nPlease note that the `fmodel()` function, while plotting for the recursive partitioning model takes in the 'first' level in the variable. You can easily check which level is represented in the y-axis by checking the level order.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(NHANES)\n\n# Checking levels\nlevels(NHANES$SmokeNow)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"No\"  \"Yes\"\n```\n:::\n:::\n\n\n\nThe level \"No\" will be represented in the y-axis for the recursive partitioning model plot. Therefore for increasing y-axis values, the probability of not smoking will increase.\n\nAfter comparing both the plots you can quickly notice that the plot for the recursive partitioning model shows step-wise change or sudden change and for the logistic model plot, the increase is gradual. Interestingly the plot shows that in higher BMI groups, i.e. in groups of obese people, a smoking habit is uncommon. Anyway, in the recursive partitioning model plot, there is a sudden increase in y-axis values between 20 and 30 in the axis. Let us calculate the effect size of both models at this range.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculating the effect size for recursive partitioning model\neffect_size_rpart <- effect_size(model_rpart, ~ BMI, BMI = 20, to = 10)\n\n# Printing the effect size for recursive partitioning \neffect_size_rpart\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope.No\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"slope.Yes\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BMI\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:BMI\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.01837502\",\"2\":\"-0.01837502\",\"3\":\"20\",\"4\":\"30\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Calculating the effect size for logistic model\neffect_size_logistic <- effect_size(model_logistic, ~ BMI, BMI = 20, to = 10)\n\n# Printing the effect size for logistic\neffect_size_logistic\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BMI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:BMI\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.00887037\",\"2\":\"20\",\"3\":\"30\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNote how the effect size for the recursive partitioning model is higher as compared to the logistic model. This is evident from the graph as the slope changes much faster at the given range of x-axis values for the recursive partitioning model as compared to the logistic model. Thus, recursive partitioning works best for sharp, discontinuous changes, whereas logistic regression can capture smooth, gradual changes.\n\nNow coming back to interpreting the values, let's take the case we just discussed. Let us take the effect sizes in the recursive partitioning model. Here, as BMI changes from 20 to 30, there is a 1.8% increased chance that the smoking habit drops. Also ass the response variable is dichotomous, the opposite happens for the other case; 1.8% reduced chance that smoking habit is seen. With such low chances, BMI might not have any association with smoking habit at that particular range of the x-axis. values.   \n\n## Plotting the model output\n\nWith the help of the `fmodel()` function in the `{statisticalModeling}` package, we can easily plot the model outputs as a plot. Let us plot some plots.\n\nWe will again use the `NHANES` dataset from the `{NHANES}` package in R. We will `DiabetesAge` as the response variable and see if it has any association with `Age`. The `Diabetes` describes the participant's age at which they were declared diabetic.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(NHANES)\nlibrary(statisticalModeling)\n\n# Building the logistic model\nmodel_logistic <- glm(Diabetes ~ Age, data = NHANES, family = \"binomial\")\n\n# Plotting the graph\nfmodel(model_logistic) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"Diabetes ~ Age (logistic model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nWe get a rather unsurprising graph. As age increases, the risk of getting diabetes increases. Let us add more variables to the model and plot them one by one. Let us add the following variables; `Gender`, `Depressed` and `Education`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(NHANES)\nlibrary(statisticalModeling)\n\n# Building the logistic model (adding gender)\nmodel_logistic <- glm(Diabetes ~ Age + Gender, data = NHANES, family = \"binomial\")\n\n# Plotting the graph\nfmodel(model_logistic) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"DiabetesAge ~ Age + Gender (logistic model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe addition of the third variable introduced the colour aesthetic to the plot. Let us add another variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(NHANES)\nlibrary(statisticalModeling)\n\n# Building the logistic model (adding depressed state)\nmodel_logistic <- glm(Diabetes ~ Age + Gender + Depressed, data = NHANES, family = \"binomial\")\n\n# Plotting the graph\nfmodel(model_logistic) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"DiabetesAge ~ Age + Gender + Depressed (logistic model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nAdding a fourth variable faceted the plot into the levels of the fourth variable. Let us add one last variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(NHANES)\nlibrary(statisticalModeling)\n\n# Building the logistic model (adding Education)\nmodel_logistic <- glm(Diabetes ~ Age + Gender + Depressed + Education,\n                      data = NHANES, family = \"binomial\")\n\n# Plotting the graph\nfmodel(model_logistic) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"DiabetesAge ~ Age + Gender + Depressed + Education (logistic model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThe plot undergoes another layer of faceting. Now we get a rather complex plot as compared to the plot with just one explanatory variable. The plot shows some interesting info. Males are more prone to become diabetic as compared to females in all the groups. For college graduates who have no depression, both sexes have a reduced chance of having diabetes at younger ages as compared to all other groups. People with high school level of education and college level education have the most chance of becoming diabetic out of all groups. I leave the rest of the interpretations to the readers.\n\nIn summary, the `fmodel()` function syntax with four explanatory variables would be;\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfmodel(response ~ var1 + var2 + var3 + var4, data = dataset)\n```\n:::\n\n\nHere, the response variable will always be plotted on the y-axis. The var1 will be plotted on the x-axis and will be the main exploratory variable that we are interested in. The var2 will assume the colour aesthetic. The var3 and var4 will invoke faceting. Therefore we have;\n\n| Variable | Plot component |\n|---|---|\n| var1 | y-axis |\n| var2 | colour |\n| var3 | facet |\n| var4 | facet |\n\n: fmodel() variables as plot components\n\n## Interactions among explanatory variables\n\nTill now, when making models, we assumed that our explanatory variables are independent of each other, i.e. their effect sizes are independent of each other. But often this is not the case in real life, we can have instances where the effect size of one variable changes with the other explanatory variables. When this happens, we say that both of those variables are interacting with each other.\n\nTo denote interacting terms in the formula, instead of a `+` sign, we use a `*`.\n\nLet us see it with an example. We will use the `SwimRecords` dataset from the `mosaicData` package in R. The dataset contains world records for 100m swimming for men and women over time from 1905 through 2004. We will build a linear model, using `time` as the response variable and, `year` and `sex` as the explanatory variable. Here `time` denotes the time of the world record.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(mosaicData)) install.packages('mosaicData')\nlibrary(mosaicData)\nlibrary(statisticalModeling)\n\n# Building the linear model\nmodel_lm <- lm(time ~ year + sex, data = SwimRecords)\n\n# Plotting the model\nfmodel(model_lm) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"time ~ year + sex (linear model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nFrom the graph, you can see that the slopes for both the lines are decreasing. This means that as years progressed, the world record times for both the sexes reduced. Also, men's record time is faster compared to women's. What happens to this plot if we introduce an interaction between `year` and `sex`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(mosaicData)) install.packages('mosaicData')\nlibrary(mosaicData)\nlibrary(statisticalModeling)\n\n# Building the linear model\nmodel_lm_int <- lm(time ~ year * sex, data = SwimRecords)\n\n# Plotting the model\nfmodel(model_lm_int) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"time ~ year * sex (linear model)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThe introduction of interacting terms seems to converge the two lines. For better comparison, use the slider to compare the plots as given below.\n\n::: {.juxtapose data-startingposition=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(mosaicData)) install.packages('mosaicData')\nlibrary(mosaicData)\nlibrary(statisticalModeling)\n\n# Building the linear model\nmodel_lm <- lm(time ~ year + sex, data = SwimRecords)\n\n# Plotting the model\nfmodel(model_lm) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"time ~ year + sex (linear model without interaction)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Building the linear model with interaction term\nmodel_lm_int <- lm(time ~ year * sex, data = SwimRecords)\n\n# Plotting the model\nfmodel(model_lm_int) + ggplot2::theme_bw() +\n  ggplot2::labs(title = \"time ~ year * sex (linear model with interaction)\")\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n:::\n\n\n:::\n\nWe get some interesting results. First of all, compared to the plot without the interaction term, the slope changes for both the sexes, in the plot with interaction terms. Also, the lines are not parallel when interaction terms are introduced, this is direct evidence showing that both `year` and `sex`  variables are truly interacting with each other. This is why with increasing years, the gap between the lines decreased, indicating a reduced effect size of sex with increasing years.\n\nTo see if this interaction term makes the model better, we can calculate the mean of the square of prediction errors (m.s.e) for each model and do a t.test using them (something we learned in the previous tutorial).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(mosaicData)) install.packages('mosaicData')\nlibrary(mosaicData)\nlibrary(statisticalModeling)\n\n# Building the linear model\nmodel_lm <- lm(time ~ year + sex, data = SwimRecords)\n\n# Building the linear model with interaction term\nmodel_lm_int <- lm(time ~ year * sex, data = SwimRecords)\n\n# Calculating the m.s.e\nt.test(mse ~ model, data = cv_pred_error(model_lm, model_lm_int))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  mse by model\nt = 6.5927, df = 6.8254, p-value = 0.0003414\nalternative hypothesis: true difference in means between group model_lm and group model_lm_int is not equal to 0\n95 percent confidence interval:\n 2.829281 6.019729\nsample estimates:\n    mean in group model_lm mean in group model_lm_int \n                  17.61413                   13.18963 \n```\n:::\n:::\n\n\nFor $\\alpha = 0.05$ level of significance, we have a p-value < 0.05. Thus we conclude that the m.s.e values between the two models are significantly different from each other. Also, from the t.test summary, we can see that the m.s.e value is lowest for the model with the interaction term as compared to the model without the interaction term. This means interaction made the model better.\n\nSome takeaway points about effect sizes, from analysing the plots are;\n\n::: {.panel-tabset}\n\n## Point 1\n\n![](images/tab_1.png)\nThe slope of the line is the effect size of the x-axis exploratory variable on the y-axis response variable.\n\n## Point 2\n\n![](images/tab_2.png)\nThe difference in y-intercepts of both the lines for a given x-axis exploratory variable value gives the effect size of the colour aesthetic on the y-axis response variable.\n\n## Point 3\n\n![](images/tab_3.png)\nIf lines are parallel, then there is no interaction between the x-axis variable and the colour aesthetic variable.\n\n## Point 4\n\n![](images/tab_4.png)\n\nThe difference between the values of the slopes tells how the colour aesthetic variable is affecting the effect size of the x-axis variable.\n\n## Point 5\n\n![](images/tab_5.png)\n\nThe rate of change of the y-intercepts tells how the x-axis variable is affecting the effect size of the colour aesthetic variable. \n\n:::\n\nNow we are equipped with a strong intuition of how the interaction between variables affects the effect size of those variables and how they can be visualized from the plot.\n\n## Polynomial regression\n\nLet us look at the `Tadpoles` dataset from the `{mosaicModel}` package in R. We saw this dataset while we learned about covariates in the previous tutorial. The dataset contains the swimming speed of tadpoles as a function of the water temperature and the water temperature at which the tadpoles had been raised. Let us plot the temperature at which the tadpoles were allowed to swim versus the maximum swimming speed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(mosaicModel)) install.packages('mosaicModel')\nlibrary(mosaicModel)\nlibrary(ggplot2)\n\ndata(Tadpoles)\n\n# Building a plot\nTadpoles |> ggplot(aes(rtemp, vmax)) + geom_point() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nNow let us try building a linear model using `vmax` as the response variable and `rtemp` as the exploratory variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaicModel)\nlibrary(statisticalModeling)\n\ndata(Tadpoles)\n\n# Building the linear model\nmodel_lm <- lm(vmax ~ rtemp, data = Tadpoles)\n\n# Plotting the model\nfmodel(model_lm) + ggplot2::geom_point(data = Tadpoles) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nWe see that the model out shows a weak relationship between the temperature at which the tadpoles were allowed to swim and the maximum swimming speed. But our intuition tells us that most of the maximum values for `vmax` peaked at temperatures of 15°C and 25°C hence, the line should curve upwards at these temperature regions. Essentially, instead of a straight line relationship, a parabolic relationship would be better for defining the relationship between `rtemp` and `vmax`. To tell the model to consider `rtemp` as a second-order variable, we use the `I()` function. So here, including `I(rtemp^2)` in the formula will inform the model to regress `vmax` against `rtemp^2`. You might be tempted to ask, why not just use `rtemp^2` in the model formula? If we use `vmax ~ rtemp^2` as the model formula, then notation wise it is equivalent to using `vmax ~ rtemp * rtemp`. If we run the model using this formula, the model will omit one of the `rtemp` variables as it is redundant to regress against a variable interacting with itself.\n\nOn a more technical note, in R, the symbols `\"+\", \"-\", \"*\" and \"^\"` are interpreted as formula operators. Therefore if `rtemp^2` is used inside the formula, it will consider it as `rtemp * rtemp`. Thus to make things right, we use the `I()` function, so that R will interpret `rtemp^2` as a new predictor with squared values.\n\nLet us plot a polynomial model for the same question as above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaicModel)\nlibrary(statisticalModeling)\n\ndata(Tadpoles)\n\n# Building the linear model with rtemp in second order using I()\nmodel_lm_2 <- lm(vmax ~ rtemp + I(rtemp^2), data = Tadpoles)\n\n# Plotting the model\nfmodel(model_lm_2) + ggplot2::geom_point(data = Tadpoles) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nMuch better plot than the earlier one. The same can also be achieved by using the `poly()` function. The syntax for it is; `poly(variable, the order)`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaicModel)\nlibrary(statisticalModeling)\n\ndata(Tadpoles)\n\n# Building the linear model with rtemp in second order using poly()\nmodel_lm_2 <- lm(vmax ~ poly(rtemp, 2), data = Tadpoles)\n\n# Plotting the model\nfmodel(model_lm_2) + ggplot2::geom_point(data = Tadpoles) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Total and partial change\n\nFrom the previous tutorial and current tutorial, we built our notion of effect size bit by bit. In a gist, the flowchart below shows our efforts till now;\n\n\n```{mermaid}\n%%{init: {'securityLevel': 'loose', 'theme':'base'}}%%\ngraph TB\n  A[Understanding effect sizes] --o B(In the context of numerical explanatory variable)\n  B --> C(In the context of categorical explanatory variable)\n  C --> D(Magnitude and the sign of effect size value)\n  D --> E(Units of effect size)\n  E --> F(In the context of categorical response variable)\n  F --> G(How interaction terms affect effect sizes:<br>Understanding it from graphs)\n  G -.-> H(How interaction terms affect effect sizes:<br>Understanding it from calculations)\n  style H fill:#f96\n  subgraph Flowchart on current understanding of effect size\n  A\n  B\n  C\n  D\n  E\n  F\n  G\n  H\n  end\n```\n\n\nFrom the flowchart, we can appreciate the growing complexity in the understanding of effect size. We have already begun to understand effect sizes in the context of interaction terms as seen from previous graphs. Now let us try to calculate effect sizes with interaction terms.\n\nWe will use the `HorsePrices` dataset from the `{Stat2Data}` package in R. The dataset contains the price and related characteristics of horses listed for sale on the internet. The variables in the dataset include; `Price` = Price of the horse ($), `HorseID` = ID of the horse, `Age` = Age of the horse, `Height` = Height of the horse and `Sex` = Sex of the horse.\n\nSuppose we are interested in the following questions\n\n1. How does the price of the horse change between sexes?\n2. How does the price of the horse change between sexes for the same height and age?\n\nIn the first question, we are checking for the price difference between the sexes. Here, when sex changes, the covariate variables; height and age of the horse will also change with sex. Therefore, here we are measuring the change in price by allowing all other variables in the model to change along with the exploratory variable sex. This is termed the 'total change in price as sex changes'.\n\nIn the second question, unlike the first, we want to specifically see what is the price difference between sexes. To see this change, we keep height and age constant. Therefore, the only change seen in this case would be coming from the sex change. This is termed the 'partial change of price as sex changes'.\n\nFor the first question, we will calculate the effect size of sex on price using the following lines of code. Since our question focuses on the total change in price with sex, we make a model by excluding all the other covariates that we want to change as sex changes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nif (!require(Stat2Data)) install.packages('Stat2Data')\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Building the linear model\nmodel_lm <- lm(Price ~ Sex, data = HorsePrices)\n\n\n# Calculating the effect size\neffect_size(model_lm, ~ Sex)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"change\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sex\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"to:Sex\"],\"name\":[3],\"type\":[\"fct\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"-17225\",\"2\":\"m\",\"3\":\"f\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe effect size value tells us that, changing from a male horse to a female, the price depreciates by 17225 dollars. Now to answer the second question, to calculate the partial change in price because of a change in sex, we build a model by including all the other covariates that we want to keep constant when we change sex.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nif (!require(Stat2Data)) install.packages('Stat2Data')\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Building the linear model\nmodel_lm_partial <- lm(Price ~ Sex + Height + Age, data = HorsePrices)\n\n# Calculating the effect size\neffect_size(model_lm_partial, ~ Sex)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"change\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sex\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"to:Sex\"],\"name\":[3],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Height\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Age\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-9928.29\",\"2\":\"m\",\"3\":\"f\",\"4\":\"16.5\",\"5\":\"6\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe effect size value, in this case, tells us that, a male horse of age 6 and 16.5m in height will be 9928 dollars more costly than a female horse of the same physical attributes. Here it's clear that for the given height and age, there is a price difference between male and female horses, something which we were trying to answer.\n\n## R-squared in terms of model output\n\nSo far we have seen metrics like the mean of the square of prediction error and likelihood values to evaluate a model's predictive abilities. In terms of variables used in the model formula, we know how to interpret them using effect sizes. There is also another metric called R-squared ($R^2$).\n\nOne of the implications of a model is to account for variations seen within the response variable to the model output values. The R-squared value tells us how well this has been done. By definition;\n\n$$R^2 = \\frac{variance\\,of\\,model\\,output\\,values}{variance\\,of\\,response\\,variable\\,values}$$\nThe R-squared value is always positive and is between 0 and 1. R-squared value of 1 means that the model accounted for all the variance seen within the actual dataset values of the response variable. R-squared value of 0 means that the model does not account for any variance seen in the response variable. \n\nBut the R-squared value has its flaws which we will see soon.\n\nLet us calculate the R-squared value for some models. We will again use the `HorsePrices` dataset from the `{Stat2Data}` package in R. Let us build the earlier model again and calculate the R-squared value for the model. We will use the `evaluate_model()` function from the `statisticalModeling` package to get the predicted values. For now, we will use the training dataset itself as the testing dataset. We will use the `var()` formula to calculate the variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Building the linear model\nmodel_lm <- lm(Price ~ Sex, data = HorsePrices)\n\n# Getting the predicted values\nmodel_lm_output <- evaluate_model(model_lm, data = HorsePrices)\n\n# Calculating the R-squared value\nr_squared <- with(data = model_lm_output, var(model_output)/var(Price))\n\n# Printing R-squared value\nr_squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3237929\n```\n:::\n:::\n\n\nWe get an R-squared value of 0.32. What this means is that 32% of the variability seen in the price of the horses is explained by the sex of the horses.\n\nNow let us add in more explanatory variables and calculate the R-squared value. We will also remove any `NA` values in the model variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Removing NA values\nHorsePrices_new <- tidyr::drop_na(HorsePrices)\n\n# Building the linear model\nmodel_lm <- lm(Price ~ Sex + Height + Age, data = HorsePrices_new)\n\n# Getting the predicted values\nmodel_lm_output <- evaluate_model(model_lm, data = HorsePrices_new)\n\n# Calculating the R-squared value\nr_squared <- with(data = model_lm_output, var(model_output)/var(Price))\n\n# Printing R-squared value\nr_squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4328061\n```\n:::\n:::\n\n\nWe got a higher R-squared value than before. Instead of 32%, we now can account for 43% of variability seen in price by all the other variables.\n\nDoes this mean that this model is better than the previous one? Before we jump in, let us do a fun little experiment. Let us see what happens if we add in random variables with no predicted power whatsoever to the model and run a model using them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Removing NA values\nHorsePrices_new <- tidyr::drop_na(HorsePrices)\n\n# Adding random variable\nset.seed(56)\nHorsePrices_new$Random <- rnorm(nrow(HorsePrices_new)) > 0\n\n# Building the linear model\nmodel_lm_random <- lm(Price ~ Sex + Height + Age + Random, data = HorsePrices_new)\n\n# Getting the predicted values\nmodel_lm_random_output <- evaluate_model(model_lm_random, data = HorsePrices_new)\n\n# Calculating the R-squared value\nr_squared <- with(data = model_lm_random_output, var(model_output)/var(Price))\n\n# Printing R-squared value\nr_squared\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4437072\n```\n:::\n:::\n\n\nWe got an R-squared value of 0.44. The random variable should throw off the model output, then why did we get a higher R-squared value?\n\nThe R-squared value of a model will increase with increasing explanatory variables. To remind you again, the R-squared value comes partly from the model output and our model output comes from the design of the model. The model design includes selecting the appropriate explanatory variables which are up to the user. Therefore, stupidly adding variables which have no relationship whatsoever with the response variable can lead us to the wrong conclusion. Let us calculate the mean square of the prediction error for our last two models and compare them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Removing NA values\nHorsePrices_new <- tidyr::drop_na(HorsePrices)\n\n# Adding random variable\nset.seed(56)\nHorsePrices_new$Random <- rnorm(nrow(HorsePrices_new)) > 0\n\n# Building the linear model\nmodel_lm <- lm(Price ~ Sex, data = HorsePrices_new)\n\n# Building the linear model with random variable\nmodel_lm_random <- lm(Price ~ Sex + Random, data = HorsePrices_new)\n\n# Calculating the mean of square of prediction errors for trials\nmodel_errors <- cv_pred_error(model_lm, model_lm_random)\n\n# Calculating the mean of square of prediction errors\nboxplot(mse ~ model, model_errors)\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Conducting t-test\nt.test(mse ~ model, model_errors)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  mse by model\nt = -2.9348, df = 6.9143, p-value = 0.02218\nalternative hypothesis: true difference in means between group model_lm and group model_lm_random is not equal to 0\n95 percent confidence interval:\n -11481425  -1221092\nsample estimates:\n       mean in group model_lm mean in group model_lm_random \n                    153536030                     159887288 \n```\n:::\n:::\n\n\nThe plot and the t.test results can be used to check if the model with the random variable is indeed a poor one compared to the model without any random variable, something the R-squared value failed to report. Therefore R-squared value has its flaw, but it is widely used by people. Therefore, we should be very careful in interpreting the R-squared values of different models. Different models made from the same data can have different R-squared values.\n\n## R-squared in terms of residuals\n\nFrom the above example, I mentioned that the R-squared value tells us how much percentage of the variability seen within the response variable is captured by the predicted model output values. Another way of seeing the same thing is through residuals. The residual is the distance between the regression line and the response variable value, or in other words, the difference between the fitted value and the corresponding response variable value. We can find R-squared using the following formula also;\n\n$$R^2 = \\frac{variance\\,of\\,response\\,variable\\,values - variance\\,of\\,residuals}{variance\\,of\\,response\\,variable\\,values}$$\n\nWe can use the following code to calculate the R-squared value via the above formula.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(Stat2Data)\nlibrary(statisticalModeling)\n\ndata(\"HorsePrices\")\n\n# Removing NA values\nHorsePrices_new <- tidyr::drop_na(HorsePrices)\n\n# Building the linear model\nmodel_lm <- lm(Price ~ Sex + Height + Age, data = HorsePrices_new)\n\n# Getting the predicted values\nmodel_lm_output <- evaluate_model(model_lm, data = HorsePrices_new)\n\n# Calculating the R-squared value using model output values\nr_squared_mo <- with(data = model_lm_output, var(model_output)/var(Price))\n\n# Calculating the R-squared value using residuals\nr_squared_res <- (var(HorsePrices_new$Price) - var(model_lm$residuals)) / var(HorsePrices_new$Price)\n\n# Checking if both R-squared values are the same\nr_squared_mo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4328061\n```\n:::\n\n```{.r .cell-code}\nr_squared_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4328061\n```\n:::\n\n```{.r .cell-code}\nround(r_squared_mo) == round(r_squared_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nAs you can see, they are both the same. Therefore, the R-squared value of 1 means that the model has zero residuals, which means that the model is a perfect fit; all data points lie on the regression line. R-squared value of 0 means that the variance of residuals is the same as that of the variance of the response variable. This means the explanatory variables we chose do not account for the variation seen within the response variable.\n\n## Bootstrapping and precision\n\nAll the datasets that we have worked on till now have been collected from a large population. Therefore, from these samples, we calculated different test statistics like the mean prediction error and effect sizes. Suppose we sample data again from the same population and calculate these test statistics, if they are close to earlier calculated values, then we can say that our test statistics are precise. But re-sampling the data is often costly and tedious to do. Then how can we check for precision? We can do that using a technique called bootstrapping. Similar to resampling, instead of collecting new samples from the population, we resample the data from the already collected data itself. Essentially, we are treating our existing dataset as a population dataset from which resampling occurs. Needless to say, this would only work effectively with large datasets.\n\n\n```{mermaid}\n%%{init: {'securityLevel': 'loose', 'theme':'base'}}%%\ngraph LR\n  A[Population] --> B(Random sample)\n  B --> C(Calculating sample statistics)\n  A --> D(Random sample)\n  D --> E(Calculating sample statistics)\n  A --> F(\"---\")\n  F --> G(\"---\")\n  A --> H(Random sample)\n  H --> I(Calculating sample statistics)\n  J[Population] --> K(Random sample)\n  J --> L(Random sample)\n  J --> M(Collected random sample)\n  M --> N(Resample 1)\n  M --> O(Resample 2)\n  M --> P(Resample 3)\n  J --> Q(Random sample)\n  subgraph Bootstrapping\n  J\n  K\n  L\n  M\n  N\n  O\n  P\n  Q\n  end\n  subgraph Resampling from the population\n  A\n  B\n  C\n  D\n  E\n  F\n  G\n  H\n  I\n  end\n```\n\n\nLet us perform a bootstrap trial code by code. We will be using the `run17` dataset from the `{cherryblossom}` package in R. It's a relatively large dataset that we can use to study how to do a bootstrap.\n\nWe will first build a model and then calculate a sample statistic, which in this case would be the effect size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nif (!require(cherryblossom)) install.packages('cherryblossom')\nlibrary(cherryblossom)\nlibrary(statisticalModeling)\nlibrary(dplyr)\n\n# Filtering the data for 10 Mile marathon participants\nrun17_marathon <- run17 %>% filter(event == \"10 Mile\")\n\n# Building a linear model\nmodel_lm <- lm(net_sec ~ age + sex, data = run17_marathon)\n\n# Calculating the effect size\neffect_size(model_lm, ~ age)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"age\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:age\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sex\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"17.91574\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nUsing the `sample()` function in R, we will sample the row indices in the original dataset. Then using these row indices, we build a resampled dataset. Then using this resampled dataset, we will build a new model and then calculate the effect size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(cherryblossom)\nlibrary(statisticalModeling)\nlibrary(dplyr)\n\n# Filtering the data for 10 Mile marathon participants\nrun17_marathon <- run17 %>% filter(event == \"10 Mile\")\n\n# Collecting the row indices \nrow_indices <- sample(1:nrow(run17_marathon), replace = T)\n\n# Resampling data using the rwo indices\nresample_data <- run17_marathon[row_indices, ]\n\n# Building a linear model\nmodel_lm_resample <- lm(net_sec ~ age + sex, data = resample_data)\n\n# Calculating the effect size\neffect_size(model_lm_resample, ~ age)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"age\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:age\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sex\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"18.08821\",\"2\":\"35\",\"3\":\"45.74382\",\"4\":\"F\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWe get a slightly different effect size value in each case. If we repeat this process, we can get multiple effect size values that we can plot to get the sampling distribution of the effect size. doing this code by code is tedious and therefore we will automate this process using the `ensemble()` function in the `statisticalModeling` package in R. Using `nreps` inside the `ensemble()` function, we can specify how many times we want to resample the data. Normally, 100 resampling trials are performed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries\nlibrary(cherryblossom)\nlibrary(statisticalModeling)\nlibrary(dplyr)\n\n# Filtering the data for 10 Mile marathon participants\nrun17_marathon <- run17 %>% filter(event == \"10 Mile\")\n\n# Building a linear model\nmodel_lm <- lm(net_sec ~ age + sex, data = run17_marathon)\n\n# Resampling 100 times\nmodel_trials <- ensemble(model_lm, nreps = 100)\n\n# Calculating the effect size for each resampled data\nresampled_effect_sizes <- effect_size(model_trials, ~ age)\n\n# Printing effect sizes\nresampled_effect_sizes\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"age\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:age\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sex\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"bootstrap_rep\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"18.52807\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"1\",\"_rn_\":\"1\"},{\"1\":\"18.62894\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"2\",\"_rn_\":\"11\"},{\"1\":\"16.96007\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"3\",\"_rn_\":\"12\"},{\"1\":\"17.13521\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"4\",\"_rn_\":\"13\"},{\"1\":\"17.72699\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"5\",\"_rn_\":\"14\"},{\"1\":\"17.26502\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"6\",\"_rn_\":\"15\"},{\"1\":\"17.84770\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"7\",\"_rn_\":\"16\"},{\"1\":\"18.21044\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"8\",\"_rn_\":\"17\"},{\"1\":\"17.72617\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"9\",\"_rn_\":\"18\"},{\"1\":\"19.14271\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"10\",\"_rn_\":\"19\"},{\"1\":\"18.21329\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"11\",\"_rn_\":\"110\"},{\"1\":\"17.74558\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"12\",\"_rn_\":\"111\"},{\"1\":\"16.81683\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"13\",\"_rn_\":\"112\"},{\"1\":\"18.49238\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"14\",\"_rn_\":\"113\"},{\"1\":\"18.16016\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"15\",\"_rn_\":\"114\"},{\"1\":\"18.25199\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"16\",\"_rn_\":\"115\"},{\"1\":\"18.19143\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"17\",\"_rn_\":\"116\"},{\"1\":\"16.23985\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"18\",\"_rn_\":\"117\"},{\"1\":\"17.13319\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"19\",\"_rn_\":\"118\"},{\"1\":\"18.76587\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"20\",\"_rn_\":\"119\"},{\"1\":\"17.02959\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"21\",\"_rn_\":\"120\"},{\"1\":\"17.70577\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"22\",\"_rn_\":\"121\"},{\"1\":\"17.61485\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"23\",\"_rn_\":\"122\"},{\"1\":\"18.58561\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"24\",\"_rn_\":\"123\"},{\"1\":\"18.50629\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"25\",\"_rn_\":\"124\"},{\"1\":\"18.00859\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"26\",\"_rn_\":\"125\"},{\"1\":\"17.44250\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"27\",\"_rn_\":\"126\"},{\"1\":\"17.57814\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"28\",\"_rn_\":\"127\"},{\"1\":\"17.65674\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"29\",\"_rn_\":\"128\"},{\"1\":\"17.94273\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"30\",\"_rn_\":\"129\"},{\"1\":\"18.36642\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"31\",\"_rn_\":\"130\"},{\"1\":\"17.78833\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"32\",\"_rn_\":\"131\"},{\"1\":\"18.03960\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"33\",\"_rn_\":\"132\"},{\"1\":\"18.01160\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"34\",\"_rn_\":\"133\"},{\"1\":\"17.49672\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"35\",\"_rn_\":\"134\"},{\"1\":\"18.70492\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"36\",\"_rn_\":\"135\"},{\"1\":\"18.17493\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"37\",\"_rn_\":\"136\"},{\"1\":\"17.95394\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"38\",\"_rn_\":\"137\"},{\"1\":\"16.66961\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"39\",\"_rn_\":\"138\"},{\"1\":\"18.85841\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"40\",\"_rn_\":\"139\"},{\"1\":\"18.69594\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"41\",\"_rn_\":\"140\"},{\"1\":\"18.89479\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"42\",\"_rn_\":\"141\"},{\"1\":\"18.72304\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"43\",\"_rn_\":\"142\"},{\"1\":\"17.73050\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"44\",\"_rn_\":\"143\"},{\"1\":\"18.20891\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"45\",\"_rn_\":\"144\"},{\"1\":\"17.74706\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"46\",\"_rn_\":\"145\"},{\"1\":\"17.45297\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"47\",\"_rn_\":\"146\"},{\"1\":\"17.78011\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"48\",\"_rn_\":\"147\"},{\"1\":\"17.78550\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"49\",\"_rn_\":\"148\"},{\"1\":\"16.75681\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"50\",\"_rn_\":\"149\"},{\"1\":\"18.26516\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"51\",\"_rn_\":\"150\"},{\"1\":\"18.42345\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"52\",\"_rn_\":\"151\"},{\"1\":\"17.70255\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"53\",\"_rn_\":\"152\"},{\"1\":\"17.47794\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"54\",\"_rn_\":\"153\"},{\"1\":\"18.33432\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"55\",\"_rn_\":\"154\"},{\"1\":\"17.74489\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"56\",\"_rn_\":\"155\"},{\"1\":\"17.77921\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"57\",\"_rn_\":\"156\"},{\"1\":\"18.23165\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"58\",\"_rn_\":\"157\"},{\"1\":\"17.42809\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"59\",\"_rn_\":\"158\"},{\"1\":\"17.36443\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"60\",\"_rn_\":\"159\"},{\"1\":\"18.20237\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"61\",\"_rn_\":\"160\"},{\"1\":\"19.60116\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"62\",\"_rn_\":\"161\"},{\"1\":\"18.42000\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"63\",\"_rn_\":\"162\"},{\"1\":\"18.27962\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"64\",\"_rn_\":\"163\"},{\"1\":\"17.01492\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"65\",\"_rn_\":\"164\"},{\"1\":\"18.47336\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"66\",\"_rn_\":\"165\"},{\"1\":\"19.24642\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"67\",\"_rn_\":\"166\"},{\"1\":\"18.56850\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"68\",\"_rn_\":\"167\"},{\"1\":\"18.06588\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"69\",\"_rn_\":\"168\"},{\"1\":\"17.25082\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"70\",\"_rn_\":\"169\"},{\"1\":\"18.53319\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"71\",\"_rn_\":\"170\"},{\"1\":\"18.67266\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"72\",\"_rn_\":\"171\"},{\"1\":\"18.38777\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"73\",\"_rn_\":\"172\"},{\"1\":\"17.68760\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"74\",\"_rn_\":\"173\"},{\"1\":\"17.60244\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"75\",\"_rn_\":\"174\"},{\"1\":\"18.95387\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"76\",\"_rn_\":\"175\"},{\"1\":\"18.16775\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"77\",\"_rn_\":\"176\"},{\"1\":\"18.57344\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"78\",\"_rn_\":\"177\"},{\"1\":\"16.91922\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"79\",\"_rn_\":\"178\"},{\"1\":\"18.19612\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"80\",\"_rn_\":\"179\"},{\"1\":\"17.52922\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"81\",\"_rn_\":\"180\"},{\"1\":\"19.48984\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"82\",\"_rn_\":\"181\"},{\"1\":\"18.62649\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"83\",\"_rn_\":\"182\"},{\"1\":\"18.04497\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"84\",\"_rn_\":\"183\"},{\"1\":\"17.03443\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"85\",\"_rn_\":\"184\"},{\"1\":\"17.26326\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"86\",\"_rn_\":\"185\"},{\"1\":\"16.58411\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"87\",\"_rn_\":\"186\"},{\"1\":\"17.69762\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"88\",\"_rn_\":\"187\"},{\"1\":\"17.18250\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"89\",\"_rn_\":\"188\"},{\"1\":\"17.65801\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"90\",\"_rn_\":\"189\"},{\"1\":\"17.01308\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"91\",\"_rn_\":\"190\"},{\"1\":\"18.08049\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"92\",\"_rn_\":\"191\"},{\"1\":\"17.72445\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"93\",\"_rn_\":\"192\"},{\"1\":\"18.66508\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"94\",\"_rn_\":\"193\"},{\"1\":\"17.74312\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"95\",\"_rn_\":\"194\"},{\"1\":\"17.23929\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"96\",\"_rn_\":\"195\"},{\"1\":\"17.56232\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"97\",\"_rn_\":\"196\"},{\"1\":\"17.39767\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"98\",\"_rn_\":\"197\"},{\"1\":\"18.16926\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"99\",\"_rn_\":\"198\"},{\"1\":\"18.49813\",\"2\":\"35\",\"3\":\"45.70635\",\"4\":\"F\",\"5\":\"100\",\"_rn_\":\"199\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNow to estimate the precision in the effect size, we can calculate its standard deviation. This is the bootstrapped estimate of the standard error of the effect size, a measure of the precision of the quantity calculated on the original model. We can also plot a histogram of the effect size values we got from each of the trails to get the sampling distribution of the effect size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculating the standard error of effect size of age\nsd(resampled_effect_sizes$slope)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.652797\n```\n:::\n\n```{.r .cell-code}\n# Plotting a histogram\nhist(resampled_effect_sizes$slope)\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n## Scales and transformations\n\nDepending on the class of the response variables, we can apply relevant transformations to change the scale of the variables to make the model better. We have seen how to use appropriate model architecture depending on the response variable, now we will see how to use relevant transformations.\n\n### Logarithmic transformation\n\nIn this exercise, we will see log-transformation which is mainly used when the response variable varies in proportion to its current size. For example, variables denoting population growth, exponential growth, prices or other money-related variables.\n\nWe will be using the `Oil_history` dataset from the `statisticalModeling` package in R. It denotes the historical production of crude oil, worldwide from 1880-2014. Let us first plot the data points and see how they are distributed. Here I am filtering the data till the year 1980 to get a nice looking exponential growth curve for the exercise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(\"Oil_history\")\n\n# Plotting the data points\nOil_history %>% filter(year < 1980) %>%\n  ggplot(aes(year, mbbl)) + geom_point() +\n  labs(y = \"mbbl (oil production in millions of barrels)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\nYou can see exponential growth in oil barrel production with increasing years. First, we will build a linear model looking at how years influenced change in barrel production. Here, `mbbl` would be our response variable and `year` our explanatory variable. Secondly, we will build another linear model but here our response variable; `mbbl` will be log-transformed. You can compare the plots using the slider.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(\"Oil_history\")\n\n# Filtering values till 1980\nOil_1980 <- Oil_history %>% filter(year < 1980)\n\n# Building a linear model\nmodel_lm <- lm(mbbl ~ year, data = Oil_1980)\n\n# Plotting the linear model\nfmodel(model_lm) + ggplot2::geom_point(data = Oil_1980) +\n  ggplot2::labs(y = \"mbbl (oil production in millions of barrels)\",\n                title = \"Oil production in millions of barrels ~ Year\") +\n  theme_bw()\n\n# Transforming mbbl values to logarithmic scale\nOil_1980$log_mbbl <- log(Oil_1980$mbbl)\n\n# Building a linear model with log transformed response variable\nmodel_lm_log <- lm(log_mbbl ~ year, data = Oil_1980)\n\n# Plotting the linear model with log transformed response variable\nfmodel(model_lm_log) + ggplot2::geom_point(data = Oil_1980) +\n  ggplot2::labs(y = \"log(mbbl) [oil production in millions of barrels]\",\n                title = \"log(Oil production in millions of barrels) ~ Year\") +\n  theme_bw()\n```\n:::\n\n\n::: {.juxtapose data-startingposition=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(\"Oil_history\")\n\n# Filtering values till 1980\nOil_1980 <- Oil_history %>% filter(year < 1980)\n\n# Building a linear model\nmodel_lm <- lm(mbbl ~ year, data = Oil_1980)\n\n# Plotting the linear model\nfmodel(model_lm) + ggplot2::geom_point(data = Oil_1980) +\n  ggplot2::labs(y = \"mbbl (oil production in millions of barrels)\",\n                title = \"Oil production in millions of barrels ~ Year\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Transforming mbbl values to logarithmic scale\nOil_1980$log_mbbl <- log(Oil_1980$mbbl)\n\n# Building a linear model with log transformed response variable\nmodel_lm_log <- lm(log_mbbl ~ year, data = Oil_1980)\n\n# Plotting the linear model with log transformed response variable\nfmodel(model_lm_log) + ggplot2::geom_point(data = Oil_1980) +\n  ggplot2::labs(y = \"log(mbbl) [oil production in millions of barrels]\",\n                title = \"log(Oil production in millions of barrels) ~ Year\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-38-2.png){width=672}\n:::\n:::\n\n\n:::\n\nIn the first graph, our linear model does not fit the values perfectly as opposed to the model which used the log transformation of the response variable. Why the second model fits better because initially `mbbl` and `Year` had an exponential relationship. But after log transformation, the relationship became a linear one and thus the model performs better. We can calculate the mean predictive error between these two models and see which one does a better job at predicting.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(dplyr)\n\ndata(\"Oil_history\")\n\n# Filtering values till 1980\nOil_1980 <- Oil_history %>% filter(year < 1980)\n\n# Transforming mbbl values to logarithmic scale\nOil_1980$log_mbbl <- log(Oil_1980$mbbl)\n\n# Building a linear model\nmodel_lm <- lm(mbbl ~ year, data = Oil_1980)\n\n# Building a linear model with log transformed response variable\nmodel_lm_log <- lm(log_mbbl ~ year, data = Oil_1980)\n\n# Evaluating the model\npredict_lm <- evaluate_model(model_lm, data = Oil_1980)\npredict_lm_log <- evaluate_model(model_lm_log, data = Oil_1980)\n\n# Transforming the model output values back to normal\npredict_lm_log$model_output_nonlog <- exp(predict_lm_log$model_output)\n\n# Calculating the mean square errors\nmean((predict_lm$mbbl - predict_lm$model_output)^2, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17671912\n```\n:::\n\n```{.r .cell-code}\nmean((predict_lm_log$mbbl - predict_lm_log$model_output_nonlog)^2, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1861877\n```\n:::\n:::\n\n\nWe get a much smaller mean predictive error for the model with log transformation as compared to the model which does not have log transformation.\n\nLet us calculate the effect size for these two models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\n\ndata(\"Oil_history\")\n\n# Building a linear model\nmodel_lm <- lm(mbbl ~ year, data = Oil_1980)\n\n# Building a linear model with log transformed response variable\nmodel_lm_log <- lm(log_mbbl ~ year, data = Oil_1980)\n\n# Calculating the effect sizes\neffect_size(model_lm, ~ year)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"year\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:year\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"254.1007\",\"2\":\"1957.5\",\"3\":\"1987.599\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\neffect_size(model_lm_log, ~ year)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"year\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:year\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.06533616\",\"2\":\"1957.5\",\"3\":\"1987.599\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nFor the model without a log-transformed response variable, we have slope = 254. This means, that from the year 1958 to 1988, the oil barrels production increased by 254 million barrels per year. What about the effect size of the model with a log-transformed response variable?\n\nThe effect size for a log-transformed value is in terms of the change of logarithm per unit of the explanatory variable. It's generally easier to interpret this as a percentage change per unit of the explanatory variable, which also involves an exponential transformation: `100 * (exp(__effect_size__) - 1)`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\n\ndata(\"Oil_history\")\n\n# Building a linear model with log transformed response variable\nmodel_lm_log <- lm(log_mbbl ~ year, data = Oil_1980)\n\n# Calculating the effect size\neffect_lm_log <- effect_size(model_lm_log, ~ year)\n\n# Converting effect size to percentage change\n100 * (exp(effect_lm_log$slope) - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.751782\n```\n:::\n:::\n\n\nWe get a value of 6.75. This means that barrel production increased by 6.75% each year from 1958 to 1988.\n\nWe can take this one step further by using the bootstrapping method and thereby calculate the effect size. Then, after converting effect size to percentage change, we can calculate the 95% confidence interval on the percentage change in oil barrel production per year.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\n\ndata(\"Oil_history\")\n\n# Building a linear model with log transformed response variable\nmodel_lm_log <- lm(log_mbbl ~ year, data = Oil_1980)\n\n# Bootstrap replications: 100 trials\nbootstrap_trials <- ensemble(model_lm_log, nreps = 100, data = Oil_1980)\n\n# Calculating the effect size\nbootstrap_effect_sizes <- effect_size(bootstrap_trials, ~ year)\n\n# Converting effect size to percentage change\nbootstrap_effect_sizes$precentage_change <- 100 * (exp(bootstrap_effect_sizes$slope) - 1)\n\n# Calculating 95% confidence interval\nwith(bootstrap_effect_sizes, mean(precentage_change) + c(-2, 2) * sd(precentage_change))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.496748 7.003000\n```\n:::\n:::\n\n\nNice! We got a narrow 95% confidence interval of [6.50, 7.00].\n\n### Rank transformation\n\nWe found that log transformation worked best for datasets showcasing exponential growth or where depicting percentage change of response variables makes more sense. Likewise, there is another transformation called rank transformation which works best with a dataset that deviates from normality and has outliers.\n\nConsider the dataset `HorsePrices` from the `Stat2Data` package in R. We will plot the prices for female horses with their age.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Stat2Data)\nlibrary(ggplot2)\n\n# Plotting the graph\nHorsePrices %>% filter(Sex == \"f\") %>%\n  ggplot(aes(Age, Price)) + geom_point() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\nYou can see that there are two outliers in the plot for y > 30000, let us label them. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Stat2Data)\nlibrary(ggplot2)\n\n# Making a function to identify outliers\nis_outlier <- function(x) {\n  x > 30000\n}\n\n# Filtering female horses and labelling the outliers\nfemale_horses <- HorsePrices %>% filter(Sex == \"f\") %>%\n  mutate(outliers = if_else(is_outlier(Price), Price, rlang::na_int))\n\n# Plotting the graph\nfemale_horses %>% filter(Sex == \"f\") %>%\n  ggplot(aes(Age, Price)) + geom_point() +\n  geom_text(aes(label = outliers), na.rm = TRUE, vjust = 1, col = \"red\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\nNow let us build a linear model with `Price` as the response variable and `Age` as the explanatory variable and then plot the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Stat2Data)\nlibrary(ggplot2)\nlibrary(statisticalModeling)\n\n# Making a function to identify outliers\nis_outlier <- function(x) {\n  x > 30000\n}\n\n# Filtering female horses and labelling the outliers\nfemale_horses <- HorsePrices %>% filter(Sex == \"f\") %>%\n  mutate(outliers = if_else(is_outlier(Price), Price, rlang::na_int))\n\n# Building the linear model\nmodel_lm <- lm(Price ~ Age, data = female_horses)\n\n# Plotting the model\nfmodel(model_lm) + geom_point(data = female_horses) +\n  geom_text(aes(label = outliers), na.rm = TRUE, vjust = 1,\n            col = \"red\", data = female_horses) +\n  scale_y_continuous(breaks = seq(0,50000,10000), limits = c(0, 50000)) +\n  labs(title = \"Linear model\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\nThe outliers might be causing an effect on the slope of the regression line. This is where rank transformation comes into place. Using the `rank()` in R, we replace the actual value with the rank which that value occupies when arranged from ascending to descending order. Let us see how the plot will be after rank transformation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Stat2Data)\nlibrary(ggplot2)\nlibrary(statisticalModeling)\n\n# Making a function to identify outliers via ranks\nis_outlier <- function(x) {\n  x > 18\n}\n\n# Filtering female horses\nfemale_horses <- HorsePrices %>% filter(Sex == \"f\")\n\n# Assigning ranks\nfemale_horses$price_rank <- rank(female_horses$Price)\n\n# Labelling outliers via ranks\nfemale_horses<- female_horses %>%\n  mutate(outliers = if_else(is_outlier(price_rank), Price, rlang::na_int))\n\n# Building the linear model\nmodel_lm_rank <- lm(price_rank ~ Age, data = female_horses)\n\n# Plotting the model\nfmodel(model_lm_rank) + geom_point(data = female_horses) +\n  geom_text(aes(label = outliers), na.rm = TRUE, vjust = 1,\n            col = \"red\", data = female_horses) +\n  labs(y = \"Ranked Price\", title = \"Linear model with ranked price\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n\nA quick comparison of both the graphs shows that the slope of the regression line has changed. For now, let us not worry if this made the model better. We will see in greater detail rank transformation in the coming tutorials. For now, keep in mind that rank transformation works best for data with outliers.\n\n## Collinearity (also called Multicollinearity)\n\nCollinearity is a phenomenon that occurs when two or more explanatory variables used in the model are in a linear relationship with each other. Consider a dataset with 'poverty' as a variable, let's say we are looking at the association between 'poverty' and other variables such as 'education' and 'income'. Now common sense tells us that, most often, education and income have a linear relationship with each other. Highly educated people often will have a high income. Therefore, changes seen in poverty status explained by education might often be a result of income rather than education itself and vice versa. In this case, we say that the variables 'education' and 'income' are colinear.\n\nLet us look at a real-life example. Let us use the `SAT` dataset from the `{mosaicData}` package in R. The SAT data looks at the link between SAT scores and measures of educational expenditures. \n\nWe will build a linear model using `sat` as the response variable. The `sat` variable denotes the average total SAT score. We will also use `expend` as the explanatory variable. The `expend` variable denotes expenditure per pupil in average daily attendance in public elementary and secondary schools, 1994-95 (in thousands of US dollars). We will also do bootstrapping and find the 95% confidence interval.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaicData)\nlibrary(statisticalModeling)\nlibrary(ggplot2)\n\n# Building a linear model\nmodel_lm <- lm(sat ~ expend, data = SAT)\n\n# Plotting the model\nfmodel(model_lm) + theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Bootstrap replications: 100 trials\nbootstrap_trials <- ensemble(model_lm, nreps = 100)\n\n# Calculating the effect sizes of salary from the bootstrap samples\nbootstrap_effect_sizes <- effect_size(bootstrap_trials, ~ expend)\n\n# Calculating the 95% confidence interval\nwith(bootstrap_effect_sizes, mean(slope) + c(-2, 2) * sd(slope))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -33.765958  -8.135405\n```\n:::\n:::\n\n\nWe get a rather surprising plot and a 95% confidence interval value. The plot suggests that with increasing college expenditure, sat scores reduce. The confidence interval is adding evidence to it by showing that the mean of the effect size lies within a negative interval. So what's happening? Should we believe our model? \n\nBefore we decide on anything, let us add a covariate to the model. We will add the variable `frac` to the model which denotes the percentage of all eligible students taking the SAT. Let us build the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaicData)\nlibrary(statisticalModeling)\nlibrary(ggplot2)\n\n# Building a linear model\nmodel_lm_cov <- lm(sat ~ expend + frac, data = SAT)\n\n# Plotting the model\nfmodel(model_lm_cov) + theme_bw()\n```\n\n::: {.cell-output-display}\n![](inter_stat_model_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Bootstrap replications: 100 trials\nbootstrap_trials_cov <- ensemble(model_lm_cov, nreps = 100)\n\n# Calculating the effect sizes of salary from the bootstrap samples\nbootstrap_effect_sizes_cov <- effect_size(bootstrap_trials, ~ expend)\n\n# Calculating the 95% confidence interval\nwith(bootstrap_effect_sizes_cov, mean(slope) + c(-2, 2) * sd(slope))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -33.765958  -8.135405\n```\n:::\n:::\n\n\nGuess we got quite the opposite result now. Let us calculate the mean prediction error using the cross-validation technique and see which of these models is better.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaicData)\nlibrary(statisticalModeling)\n\n# Building a linear model\nmodel_lm <- lm(sat ~ expend, data = SAT)\n\n# Building a linear model with covariate\nmodel_lm_cov <- lm(sat ~ expend + frac, data = SAT)\n\n# Calculating the m.s.e values\ntrials_mse <- cv_pred_error(model_lm, model_lm_cov)\n\n# Printing mse\ntrials_mse\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mse\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"model\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"5005.516\",\"2\":\"model_lm\"},{\"1\":\"4858.050\",\"2\":\"model_lm\"},{\"1\":\"4906.532\",\"2\":\"model_lm\"},{\"1\":\"4936.597\",\"2\":\"model_lm\"},{\"1\":\"4900.786\",\"2\":\"model_lm\"},{\"1\":\"1165.439\",\"2\":\"model_lm_cov\"},{\"1\":\"1127.709\",\"2\":\"model_lm_cov\"},{\"1\":\"1171.935\",\"2\":\"model_lm_cov\"},{\"1\":\"1161.813\",\"2\":\"model_lm_cov\"},{\"1\":\"1122.860\",\"2\":\"model_lm_cov\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Doing a t.test\nt.test(mse ~ model, trials_mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  mse by model\nt = 142.26, df = 5.3575, p-value = 8.603e-11\nalternative hypothesis: true difference in means between group model_lm and group model_lm_cov is not equal to 0\n95 percent confidence interval:\n 3704.738 3838.352\nsample estimates:\n    mean in group model_lm mean in group model_lm_cov \n                  4921.496                   1149.951 \n```\n:::\n:::\n\n\nFrom the t.test results, the model with the covariate has a lower mean prediction error value as compared to the model without the covariate. Adding `frac` as the covariate seems to significantly improve our model.\n\nThe reason why I emphasized covariates is because collinearity is introduced to the model as a result of our choice of covariates. To check for collinearity, we build a linear model with our group of explanatory variables that we want to check. Then we will find the R-squared value from the model, the greater the R-squared value, the greater the collinearity between these variables. Let us find the collinearity between `expend` and `frac`. We can either use the `summary()` function to get the model summary and then get the R-squared value from the summary or use the `rsquared()` function from the `{mosaic}` package in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(mosaic)) install.packages('mosaic')\nlibrary(mosaicData)\nlibrary(mosaic)\n\n# Building a linear model\nmodel_cov <- lm(expend ~ frac, data = SAT)\n\n# Getting the summary of the model to get Rsquared value\nsummary(model_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = expend ~ frac, data = SAT)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7951 -0.7441 -0.2177  0.5983  2.8197 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.84179    0.26101  18.550  < 2e-16 ***\nfrac         0.03018    0.00592   5.097 5.78e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.109 on 48 degrees of freedom\nMultiple R-squared:  0.3512,\tAdjusted R-squared:  0.3377 \nF-statistic: 25.98 on 1 and 48 DF,  p-value: 5.781e-06\n```\n:::\n\n```{.r .cell-code}\n# Getting the Rsquared value\nrsquared(model_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3512072\n```\n:::\n:::\n\n\nFrom the model summary, the value that we are interested in is given in the 'Multiple R-squared' section, which is 0.35, which is the same as the output given by the `rsquared()` function. The value of 0.35 means that 35% of the variation seen in the `expend` variable is explained by `frac`. This suggests that there is some level of redundancy between the `expend` and `frac`. Greater the R-squared value, the greater the redundancy between the variables.\n\nR-squared is also represented in a different way called 'variance inflation factor (VIF)' which measures the factor by which the correlations amongst the predictor variables inflate the variance of the standard error of the effect size. Okay, that was a handful, let us see what this means. First, let us see the formula for VIF;\n\n$$VIF = \\frac{1}{1-R^2}$$\n\nHere, if we have an R-squared value of 0, which means there is no collinearity between the variables, then VIF would be 1. Let us assume we get a VIF value of 2. In the current context, this means that the variance of the effect sizes calculated from bootstrap trials is increased by a factor of 2. If variance increases, then the standard error associated with the effect sizes increases and thereby it will lead to reduced precision. A result of collinearity is often getting a wider confidence interval thereby giving us an unprecise estimation of; for example effect sizes in this case.\n\nIf we take the square root of VIF, then we get the 'standard error inflation factor' which tells us by how much factor the standard error of the effect sizes calculated from bootstrap trails inflate.\n\nLet us see all this in action from the codes below;\n\nWe will add another covariate to our earlier model; `salary`. The variable `salary` denotes the estimated average annual salary of teachers in public elementary and secondary schools.\n\nLet us first check for collinearity between the `salary` and `expend`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaic)\nlibrary(mosaicData)\n\n# Building a linear model to check collinearity\nmodel_collinear_salary <- lm(expend ~ salary, data = SAT)\n\n# Getting the Rsquared value\nrsquared(model_collinear_salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7565547\n```\n:::\n:::\n\n\nLooks like we opened Pandora's box. Now let us build two models, one without salary and one with salary and, see how the prediction error of the effect sizes changes. The two models will have the SAT scores as the response variable. We will calculate the standard error of effect sizes within the `effect_size()` formula by assigning `bootstrap = TRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(mosaicData)\n\n# Model 1 without salary\nmodel_1 <- lm(sat ~ expend, data = SAT)\n\n# Model 2 with salary\nmodel_2 <- lm(sat ~ expend + salary, data = SAT)\n\n# Calculating effect sizes and standard error via bootstrapping\nhead(effect_size(model_1, ~ expend, bootstrap = TRUE), n = 1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"stderr_effect\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"expend\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:expend\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-20.89217\",\"2\":\"5\",\"3\":\"5.7675\",\"4\":\"7.130307\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nhead(effect_size(model_2, ~ expend, bootstrap = TRUE), n = 1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"stderr_effect\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"expend\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:expend\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"salary\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.4677801\",\"2\":\"11\",\"3\":\"5.7675\",\"4\":\"7.130307\",\"5\":\"33.2875\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nYou can see that the standard error has increased which is due to the effect of collinearity between `expend` and `salary`.\n\nThe `statisticalModeling` package comes with the `collinearity()` function which can be used to calculate how much the effect size might (at a maximum) be influenced by collinearity with the other explanatory variables. Essentially, the `collinearity()` function calculates the square root of VIF which denotes the inflation of standard errors. Let us check the collinearity between `expend` and `salary` variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(mosaicData)\n\n# Calculating the collinearity\ncollinearity(~ expend + salary, data = SAT)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"expl_vars\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"SeIF\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"expend\",\"2\":\"2.026746\"},{\"1\":\"salary\",\"2\":\"2.026746\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nInteraction between collinear variables can also increase the standard error of effect size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(mosaicData)\n\n# Model 3 with salary interaction\nmodel_3 <- lm(sat ~ expend * salary, data = SAT)\n\n# Calculating effect sizes and standard error via bootstrapping\nhead(effect_size(model_3, ~ expend, bootstrap = TRUE), n = 1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"slope\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"stderr_effect\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"expend\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"to:expend\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"salary\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-7.792263\",\"2\":\"14\",\"3\":\"5.7675\",\"4\":\"7.130307\",\"5\":\"33.2875\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAs you can see, we got a higher standard error value as compared to model_1. Let us also calculate the mean prediction error for the three models we created.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(statisticalModeling)\nlibrary(mosaicData)\nlibrary(dplyr)\n\n# Building the models\nmodel_1 <- lm(sat ~ expend, data = SAT)\nmodel_2 <- lm(sat ~ expend + salary, data = SAT)\nmodel_3 <- lm(sat ~ expend * salary, data = SAT)\n\n# Calculating the mean prediction error for 100 trials\nmodel_mse <- cv_pred_error(model_1, model_2, model_3, ntrials = 100)\n\n# Calculating the mean and sd of mse\nmodel_mse_mean <- model_mse %>% group_by(model) %>%\n  summarise(mean = mean(mse),\n            sd = sd(mse))\n\n# Printing the mean and sd of mse\nmodel_mse_mean\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sd\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"model_1\",\"2\":\"4980.035\",\"3\":\"91.9569\"},{\"1\":\"model_2\",\"2\":\"4881.252\",\"3\":\"112.7638\"},{\"1\":\"model_3\",\"2\":\"4855.465\",\"3\":\"126.5202\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nSince I did not set seed, you might not get the same results as I got. But essentially we can use the mean prediction error values to also choose the better model out of the three.\n\nIn the end, from these two tutorials, we can sum up our criteria for model comparison. We should check for the following while doing the comparison;\n\n-   Cross-validated prediction error\n-   Inflation due to collinearity\n-   The standard error of effect size\n\n## Conclusion\n\nFirst of all, congratulations on completing the intermediate statistical modelling tutorial (bonus points if you completed the introduction tutorial also). In a nutshell, this is what we have learned from this tutorial;\n\n1. Interpreting effect size when the response variable is categorical\n\n2. Plotting model output using the `fmodel()` function from the `{statisticalModeling}` package\n\n3. Interaction terms\n\n4. Polynomial regression\n\n5. Total and partial change\n\n6. Interpreting the R-squared value in terms of model output and residuals\n\n7. Bootstrapping technique to measure the precision of model statistics\n\n8. Scales and transformation\n    * Log transformation\n    * Rank transformation\n    \n9. Collinearity\n\nYou have mastered almost everything that is there in linear modelling. Congratulations! But, the journey is not over. The next stop is 'Generalized Linear Models in R`. This is a realm where we deal with complex datasets that cannot be analysed by our trusty linear regression models. Anyway, that's a problem for tomorrow. Practice the concepts you gained from both the tutorials and come ready for the next tutorial ✌️\n\n<a hidden href=\"https://info.flagcounter.com/ynrK\"><img src=\"https://s11.flagcounter.com/count2/ynrK/bg_000000/txt_FFFFFF/border_F0F0F0/columns_5/maxflags_25/viewers_0/labels_1/pageviews_1/flags_0/percent_0/\" alt=\"Flag Counter\" border=\"0\"/></a>",
    "supporting": [
      "inter_stat_model_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}