{
  "hash": "42ce05bd93e13ae54269694017e02ced",
  "result": {
    "markdown": "---\ntitle: \"Hierarchical and Mixed Effects Models in R\"\ndescription: \"Go beyond linear models and extend your skills to analyse non-normal datasets with random effects\"\ndate: \"08/28/2022\"\ndate-modified: last-modified\nbibliography: references_glmer.bib\nformat:\n  html:\n    css:\n      - https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css\nimage: images/stat_model_4.png\ncategories: [statistical modelling]\nfilters:\n   - social-share\nshare:\n  permalink: \"https://sciquest.netlify.app/tutorials/stat_model/glmer_stat_model.html\"\n  description: \"Hierarchical and Mixed Effects Models in R\"\n  twitter: true\n  facebook: true\n  reddit: true\n  stumble: true\n  tumblr: true\n  linkedin: true\n  email: true\n---\n\n\n:::{.callout-note}\n## TL;DR\n\nIn this article you will learn;\n\n1.    What is a hierarchical model/mixed effects model?\n\n2.    What are fixed effects and random effects?\n\n3.    Building a linear mixed effects model\n\n4.    Adding random intercept group and random effect slope\n\n5.    Random effect syntaxes used in `{lme4}` packages\n\n6.    Plotting linear mixed effects model, the residuals and the confidence intervals\n\n7.    Model comparison using ANOVA\n\n8.    Building generalized mixed effects models: *Logistic* and *Poisson*\n\n9.    Plotting generalized mixed effects models\n\n10.   Repeated measures data\n\n11.   Paired t-test and repeated measures ANOVA is a special case of mixed effects model\n\n:::\n\n## Prologue\n\nThis is the fourth tutorial in the series: Statistical modelling using R. Over the past three tutorials we learned about linear models and generalized linear models. In this tutorial, we will learn how to build and understand both linear mixed effect models and generalised linear mixed effect models. They are needed to analyse datasets which have nested structures. We will learn more about it in the coming sections.\n\n## Making life easier\n\nPlease install and load the necessary packages and datasets which are listed below for a seamless tutorial session. (Not required but can be very helpful if you are following this tutorial code by code)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run the following lines of code\n\n# Packages used in this tutorial\ntutorial_packages <- rlang::quos(AER, broom, lme4, broom.mixed, ggeffects,\n                                 lmerTest, datasets)\n\n# Install required packages\nlapply(lapply(tutorial_packages, rlang::quo_name),\n  install.packages,\n  character.only = TRUE\n)\n\n# Loading the libraries\nlapply(lapply(tutorial_packages, rlang::quo_name),\n  library,\n  character.only = TRUE\n)\n\n# Datasets used in this tutorial\ndata(\"CASchools\")\ndata(\"CreditCard\")\ndata(\"RecreationDemand\")\ndata(\"sleep\")\n```\n:::\n\n\n## What is a hierarchical model?\n\nConsider a dataset of test scores of students in different classrooms across different schools. If we take a closer look into this dataset, we can see that students can be grouped into their respective genders. This group of genders will be 'nested' in the group of students. Likewise the student group is nested inside the group of classrooms which is further nested into the group of schools. This is shown in the flowchart given below (Use the scroll bar below the flowchart to navigate).\n\n\n```{mermaid}\n%%{init: {'securityLevel': 'loose', 'theme':'base'}}%%\nflowchart TB\n  A[Education] --> B(School 1)\n  A --> C(School 2)\n  A --> D(School 3)\n  B --> E(Classroom 1)\n  B --> F(Classroom 2)\n  C --> G(Classroom 1)\n  D --> H(Classroom 1)\n  D --> I(Classroom 2)\n  D --> J(Classroom 3)\n  E --> K(Males: 30, Females: 25)\n  F --> L(Males: 15, Females: 45)\n  G --> M(Males: 23, Females: 10)\n  H --> N(Males: 10, Females: 40)\n  I --> O(Males: 0, Females: 30)\n  J --> P(Males: 45, Females: 0)\n  K --> Q(Test scores)\n  L --> R(Test scores)\n  M --> S(Test scores)\n  N --> T(Test scores)\n  O --> U(Test scores)\n  P --> V(Test scores)\n  subgraph G_1[Schools]\n  B\n  C\n  D\n  end\n  style G_1 fill:#f77f00\n  subgraph G_2[Classrooms]\n  E\n  F\n  G\n  H\n  I\n  J\n  end\n  style G_2 fill:#fcbf49\n  subgraph G_3[Students]\n  K\n  L\n  M\n  N\n  O\n  P\n  end\n  style G_3 fill:#eae2b\n  subgraph G_4[Test Scores]\n  Q\n  R\n  S\n  T\n  U\n  V\n  end\n  style G_4 fill:#f8f1ae\n```\n\n\nStudent test scores are nested under the group of students. Students themselves form a group of males and females. Building from this, students are nested under classrooms. Now classrooms follow the same route and group themselves inside schools which further forms yet another group. This is an example of nested data or hierarchical data where the data is nested within itself or has a well-defined hierarchy within itself.\n\nLet us take a scenario where we are introducing a new study method to students which have the potential to raise test scores. We can train students using the new method and compare the test scores to the earlier test scores before the introduction of the novel method.\n\nOur goal is to see if the new study method imparts an effect on the test scores of students and we hypothesise that it will improve the scores. But because of the nature of the data, the test scores can also be affected by the sample size of the students, the sex of the student, the classroom and the school, all of which can impact the test scores. Further, we are sampling the scores of the same students over time after the introduction of the novel test method. This makes the test scores a repeated measure variable and they are not independent across time. Thus our dataset is both nested and sampled across time.\n\nSo how do we test if the novel study method affects the test scores by accounting for nestedness and repeated measures?\n\nWe can see that linear models won't do a good job at this. Then, from our understanding of generalized linear models, we might be able to tackle this question. Since we test scores which count data, we can use the Poisson model to predict 'test scores' using 'test method' as our main explanatory variable and use other variables like student sex, classroom size, school etc. as covariates. But in doing so we are also including the variances in test scores resulting from all the covariates present in our data. This is where mixed effect models or hierarchical models shine as they treat the covariates as 'random effects' and pool shared information on the means of the test scores across different groups. Mixed effect models try to account for the nestedness of the data by eliminating some of the variance brought by the random effect variables on the response variable by 'controlling' them. Also, since we have different sample sizes for classroom students, classrooms with lower sample sizes will be impacted more by outliers. Thus treating classroom size as a random effect can mitigate this problem.\n\nHere, the 'random effects' are the variables; sex of the student, classroom size, and school and the 'fixed effect', which is the variable that we are interested in, is the study method. A statistical model which has both random and fixed effect variables is called a 'mixed effect' model or a 'hierarchical' model.\n\nThe definitions of random effect and fixed effect are ambiguous in the scientific literature and there are multiple definitions of what constitutes a random effect and a fixed effect [@gelman_analysis_2005]. \n\nGelman [-@gelman_analysis_2005] suggest parting ways with the terms 'random' and 'fixed' and propose to view them as *constant* and *varying*;\n\n>We define effects (or coefficients) in a multilevel model as *constant* if they are identical for all groups in a population and *varying* if they are allowed to differ from group to group. For example, the model $y_{ij} = α_j +βx_{ij}$ (of units i in groups j ) has a constant slope and varying intercepts, and $y_{ij} = α_j + β_j x_{ij}$ has varying slopes and intercepts. [@gelman_analysis_2005]\n\n## Building a mixed-effects model\n\nWe will start with a linear mixed-effects model. As seen before, we use this if our residuals follow a normal or simply if our data is normally distributed. If we have count data or binomial data which is not normally distributed, then instead of building a linear mixed effects model we build a generalized linear mixed effects model. We will use the `{lme4}` package in R to build these models.\n\nWe will be using the `CASchools` dataset from the `{AER}` package in R. The dataset contains test scores which are on the Stanford 9 standardized test administered to 5th-grade students. The dataset has values for 420 elementary schools and the test scores are given as the mean score in reading and their ability to do maths. Other variables correspond to the school characteristics which we will see later along the way.\n\n## Linear mixed effects model\n\nWith the `CASchools` dataset, we are interested in seeing if the reading scores (`read`) are predicted by the school expenditure (`expenditure`). Let us start by plotting the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(AER)) install.packages('AER')\nlibrary(AER)\nlibrary(ggplot2)\n\ndata(\"CASchools\")\n\n# Plotting the data\nggplot(CASchools, aes(expenditure, read)) + geom_point() +\n  theme_bw() + labs(title = \"Reading scores vs Expenditure\",\n                    x = \"Expenditure per student (in dollars)\",\n                    y = \"Average reading score\")\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThere does not seem to be a general trend that higher expenditure leads to higher scores. Also, most counties tend to have expenditures between 4500 and 5500 dollars.\n\nNow let us try to build a linear model to predict the average reading score (`read`) with expenditure per student (`expenditure`) using the `lm()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(broom)) install.packages('broom')\nlibrary(AER)\nlibrary(broom)\n\ndata(\"CASchools\")\n\n# Building a linear model\nmodel_lm <- lm(read ~ expenditure, data = CASchools)\n\n# Extracting coefficients from the model\ntidy(model_lm)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"6.182486e+02\",\"3\":\"8.100707489\",\"4\":\"76.32033\",\"5\":\"1.576607e-247\"},{\"1\":\"expenditure\",\"2\":\"6.912466e-03\",\"3\":\"0.001514148\",\"4\":\"4.56525\",\"5\":\"6.570563e-06\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nFrom the coefficient values, we can see that the slope value for expenditure per student is almost zero. This was more or less visible to us from the plot. So does it mean that expenditure has no association with the average reading scores? Before jumping to a conclusion, if we take a closer look at the data, we can see that the scores are nested within counties (`county`). So let us try adding the variable `county` to the linear model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AER)\nlibrary(broom)\n\ndata(\"CASchools\")\n\n# Building a linear model\nmodel_lm <- lm(read ~ expenditure + county, data = CASchools)\n\n# Extracting coefficients from the model\ntidy(model_lm)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"6.858039e+02\",\"3\":\"18.525760642\",\"4\":\"37.0189309\",\"5\":\"4.040301e-127\"},{\"1\":\"expenditure\",\"2\":\"9.077844e-04\",\"3\":\"0.001478371\",\"4\":\"0.6140437\",\"5\":\"5.395597e-01\"},{\"1\":\"countyButte\",\"2\":\"-4.469788e+01\",\"3\":\"17.241321172\",\"4\":\"-2.5924856\",\"5\":\"9.902128e-03\"},{\"1\":\"countyCalaveras\",\"2\":\"-2.738092e+01\",\"3\":\"22.582896733\",\"4\":\"-1.2124626\",\"5\":\"2.261007e-01\"},{\"1\":\"countyContra Costa\",\"2\":\"-1.544451e+01\",\"3\":\"17.120866542\",\"4\":\"-0.9020868\",\"5\":\"3.675914e-01\"},{\"1\":\"countyEl Dorado\",\"2\":\"-2.244417e+01\",\"3\":\"16.794043740\",\"4\":\"-1.3364361\",\"5\":\"1.822193e-01\"},{\"1\":\"countyFresno\",\"2\":\"-5.503647e+01\",\"3\":\"16.655706026\",\"4\":\"-3.3043615\",\"5\":\"1.043858e-03\"},{\"1\":\"countyGlenn\",\"2\":\"-2.519816e+01\",\"3\":\"18.647714802\",\"4\":\"-1.3512733\",\"5\":\"1.774247e-01\"},{\"1\":\"countyHumboldt\",\"2\":\"-2.650967e+01\",\"3\":\"16.460972127\",\"4\":\"-1.6104562\",\"5\":\"1.081419e-01\"},{\"1\":\"countyImperial\",\"2\":\"-5.319224e+01\",\"3\":\"17.332936645\",\"4\":\"-3.0688535\",\"5\":\"2.305544e-03\"},{\"1\":\"countyInyo\",\"2\":\"-2.771493e+01\",\"3\":\"22.612621444\",\"4\":\"-1.2256398\",\"5\":\"2.211055e-01\"},{\"1\":\"countyKern\",\"2\":\"-5.291556e+01\",\"3\":\"16.332888797\",\"4\":\"-3.2398166\",\"5\":\"1.303177e-03\"},{\"1\":\"countyKings\",\"2\":\"-4.219708e+01\",\"3\":\"16.883861201\",\"4\":\"-2.4992555\",\"5\":\"1.287339e-02\"},{\"1\":\"countyLake\",\"2\":\"-4.818474e+01\",\"3\":\"19.544907603\",\"4\":\"-2.4653346\",\"5\":\"1.413684e-02\"},{\"1\":\"countyLassen\",\"2\":\"-2.671234e+01\",\"3\":\"17.591470576\",\"4\":\"-1.5184822\",\"5\":\"1.297377e-01\"},{\"1\":\"countyLos Angeles\",\"2\":\"-4.535997e+01\",\"3\":\"16.351665488\",\"4\":\"-2.7740277\",\"5\":\"5.814300e-03\"},{\"1\":\"countyMadera\",\"2\":\"-3.755584e+01\",\"3\":\"17.501873963\",\"4\":\"-2.1458184\",\"5\":\"3.253059e-02\"},{\"1\":\"countyMarin\",\"2\":\"-6.544586e+00\",\"3\":\"16.910911936\",\"4\":\"-0.3870037\",\"5\":\"6.989736e-01\"},{\"1\":\"countyMendocino\",\"2\":\"-4.863217e+01\",\"3\":\"22.547689601\",\"4\":\"-2.1568581\",\"5\":\"3.165339e-02\"},{\"1\":\"countyMerced\",\"2\":\"-5.532178e+01\",\"3\":\"16.737190885\",\"4\":\"-3.3053207\",\"5\":\"1.040394e-03\"},{\"1\":\"countyMonterey\",\"2\":\"-5.155600e+01\",\"3\":\"17.135352049\",\"4\":\"-3.0087507\",\"5\":\"2.800895e-03\"},{\"1\":\"countyNevada\",\"2\":\"-2.145148e+01\",\"3\":\"16.847068718\",\"4\":\"-1.2733062\",\"5\":\"2.037002e-01\"},{\"1\":\"countyOrange\",\"2\":\"-3.770660e+01\",\"3\":\"16.778473836\",\"4\":\"-2.2473202\",\"5\":\"2.520193e-02\"},{\"1\":\"countyPlacer\",\"2\":\"-2.150307e+01\",\"3\":\"16.770161517\",\"4\":\"-1.2822220\",\"5\":\"2.005590e-01\"},{\"1\":\"countyRiverside\",\"2\":\"-5.148077e+01\",\"3\":\"17.956121231\",\"4\":\"-2.8670317\",\"5\":\"4.377954e-03\"},{\"1\":\"countySacramento\",\"2\":\"-5.234992e+01\",\"3\":\"17.129186206\",\"4\":\"-3.0561827\",\"5\":\"2.402728e-03\"},{\"1\":\"countySan Benito\",\"2\":\"-4.140062e+01\",\"3\":\"18.498866431\",\"4\":\"-2.2380086\",\"5\":\"2.580854e-02\"},{\"1\":\"countySan Bernardino\",\"2\":\"-4.212670e+01\",\"3\":\"16.840840694\",\"4\":\"-2.5014608\",\"5\":\"1.279483e-02\"},{\"1\":\"countySan Diego\",\"2\":\"-3.126043e+01\",\"3\":\"16.378928121\",\"4\":\"-1.9085763\",\"5\":\"5.708203e-02\"},{\"1\":\"countySan Joaquin\",\"2\":\"-4.710529e+01\",\"3\":\"17.360009913\",\"4\":\"-2.7134369\",\"5\":\"6.966916e-03\"},{\"1\":\"countySan Luis Obispo\",\"2\":\"-2.244609e+01\",\"3\":\"19.621419211\",\"4\":\"-1.1439586\",\"5\":\"2.533725e-01\"},{\"1\":\"countySan Mateo\",\"2\":\"-2.151576e+01\",\"3\":\"16.432616845\",\"4\":\"-1.3093328\",\"5\":\"1.912255e-01\"},{\"1\":\"countySanta Barbara\",\"2\":\"-2.405862e+01\",\"3\":\"16.725421998\",\"4\":\"-1.4384463\",\"5\":\"1.511437e-01\"},{\"1\":\"countySanta Clara\",\"2\":\"-2.549658e+01\",\"3\":\"16.379703998\",\"4\":\"-1.5565961\",\"5\":\"1.204122e-01\"},{\"1\":\"countySanta Cruz\",\"2\":\"-1.404995e+01\",\"3\":\"17.057015110\",\"4\":\"-0.8237048\",\"5\":\"4.106323e-01\"},{\"1\":\"countyShasta\",\"2\":\"-3.067002e+01\",\"3\":\"16.596496414\",\"4\":\"-1.8479818\",\"5\":\"6.539432e-02\"},{\"1\":\"countySiskiyou\",\"2\":\"-3.803616e+01\",\"3\":\"16.804255031\",\"4\":\"-2.2634841\",\"5\":\"2.417833e-02\"},{\"1\":\"countySonoma\",\"2\":\"-2.332471e+01\",\"3\":\"16.248526999\",\"4\":\"-1.4354970\",\"5\":\"1.519813e-01\"},{\"1\":\"countyStanislaus\",\"2\":\"-3.319736e+01\",\"3\":\"17.190596580\",\"4\":\"-1.9311348\",\"5\":\"5.422179e-02\"},{\"1\":\"countySutter\",\"2\":\"-3.549151e+01\",\"3\":\"17.415980907\",\"4\":\"-2.0378704\",\"5\":\"4.226613e-02\"},{\"1\":\"countyTehama\",\"2\":\"-3.718844e+01\",\"3\":\"17.029523532\",\"4\":\"-2.1837630\",\"5\":\"2.960043e-02\"},{\"1\":\"countyTrinity\",\"2\":\"-1.464436e+01\",\"3\":\"19.540577296\",\"4\":\"-0.7494331\",\"5\":\"4.540673e-01\"},{\"1\":\"countyTulare\",\"2\":\"-5.296280e+01\",\"3\":\"16.426377453\",\"4\":\"-3.2242530\",\"5\":\"1.374067e-03\"},{\"1\":\"countyTuolumne\",\"2\":\"-3.234726e+01\",\"3\":\"17.278221971\",\"4\":\"-1.8721404\",\"5\":\"6.196736e-02\"},{\"1\":\"countyVentura\",\"2\":\"-4.442150e+01\",\"3\":\"16.933648929\",\"4\":\"-2.6232682\",\"5\":\"9.065403e-03\"},{\"1\":\"countyYuba\",\"2\":\"-2.649214e+01\",\"3\":\"19.579118046\",\"4\":\"-1.3530812\",\"5\":\"1.768470e-01\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThere are a total of 45 counties, so we get 44 intercept values and a global intercept value for the first county in the dataset (which is Alameda). We can also see that the slope for expenditure decreased furthermore and the standard error for the slope estimate also decreased as compared to the previous model. As for the intercepts for the respective counties, all counties as compared to Alameda county have negative intercepts. Now let us check the coefficients for the respective counties without any base county comparisons.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AER)\nlibrary(broom)\n\ndata(\"CASchools\")\n\n# Building a linear model\nmodel_lm <- lm(read ~ expenditure + county - 1, data = CASchools)\n\n# Extracting coefficients from the model\ntidy(model_lm)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"expenditure\",\"2\":\"9.077844e-04\",\"3\":\"0.001478371\",\"4\":\"0.6140437\",\"5\":\"5.395597e-01\"},{\"1\":\"countyAlameda\",\"2\":\"6.858039e+02\",\"3\":\"18.525760642\",\"4\":\"37.0189309\",\"5\":\"4.040301e-127\"},{\"1\":\"countyButte\",\"2\":\"6.411060e+02\",\"3\":\"10.737070278\",\"4\":\"59.7095818\",\"5\":\"2.640817e-193\"},{\"1\":\"countyCalaveras\",\"2\":\"6.584229e+02\",\"3\":\"17.883010198\",\"4\":\"36.8183504\",\"5\":\"1.992404e-126\"},{\"1\":\"countyContra Costa\",\"2\":\"6.703593e+02\",\"3\":\"9.848233702\",\"4\":\"68.0689925\",\"5\":\"8.544138e-213\"},{\"1\":\"countyEl Dorado\",\"2\":\"6.633597e+02\",\"3\":\"9.329227870\",\"4\":\"71.1055295\",\"5\":\"2.239244e-219\"},{\"1\":\"countyFresno\",\"2\":\"6.307674e+02\",\"3\":\"9.210621571\",\"4\":\"68.4826072\",\"5\":\"1.048519e-213\"},{\"1\":\"countyGlenn\",\"2\":\"6.606057e+02\",\"3\":\"11.238868379\",\"4\":\"58.7786662\",\"5\":\"5.356547e-191\"},{\"1\":\"countyHumboldt\",\"2\":\"6.592942e+02\",\"3\":\"8.936065532\",\"4\":\"73.7790223\",\"5\":\"5.662711e-225\"},{\"1\":\"countyImperial\",\"2\":\"6.326116e+02\",\"3\":\"9.888525559\",\"4\":\"63.9743110\",\"5\":\"1.634297e-203\"},{\"1\":\"countyInyo\",\"2\":\"6.580889e+02\",\"3\":\"17.690862762\",\"4\":\"37.1993686\",\"5\":\"9.657695e-128\"},{\"1\":\"countyKern\",\"2\":\"6.328883e+02\",\"3\":\"8.230186712\",\"4\":\"76.8984121\",\"5\":\"2.765640e-231\"},{\"1\":\"countyKings\",\"2\":\"6.436068e+02\",\"3\":\"9.427912988\",\"4\":\"68.2660914\",\"5\":\"3.139938e-213\"},{\"1\":\"countyLake\",\"2\":\"6.376191e+02\",\"3\":\"14.128739644\",\"4\":\"45.1292282\",\"5\":\"2.087400e-153\"},{\"1\":\"countyLassen\",\"2\":\"6.590915e+02\",\"3\":\"10.210426070\",\"4\":\"64.5508340\",\"5\":\"7.530591e-205\"},{\"1\":\"countyLos Angeles\",\"2\":\"6.404439e+02\",\"3\":\"8.079251545\",\"4\":\"79.2701994\",\"5\":\"6.198302e-236\"},{\"1\":\"countyMadera\",\"2\":\"6.482480e+02\",\"3\":\"10.910911822\",\"4\":\"59.4128172\",\"5\":\"1.425780e-192\"},{\"1\":\"countyMarin\",\"2\":\"6.792593e+02\",\"3\":\"10.707939857\",\"4\":\"63.4351029\",\"5\":\"2.967843e-202\"},{\"1\":\"countyMendocino\",\"2\":\"6.371717e+02\",\"3\":\"18.307394675\",\"4\":\"34.8040613\",\"5\":\"2.389305e-119\"},{\"1\":\"countyMerced\",\"2\":\"6.304821e+02\",\"3\":\"9.100504022\",\"4\":\"69.2799066\",\"5\":\"1.894476e-215\"},{\"1\":\"countyMonterey\",\"2\":\"6.342479e+02\",\"3\":\"9.734604375\",\"4\":\"65.1539421\",\"5\":\"3.085545e-206\"},{\"1\":\"countyNevada\",\"2\":\"6.643524e+02\",\"3\":\"9.788108077\",\"4\":\"67.8734205\",\"5\":\"2.312638e-212\"},{\"1\":\"countyOrange\",\"2\":\"6.480972e+02\",\"3\":\"8.792466757\",\"4\":\"73.7105146\",\"5\":\"7.838486e-225\"},{\"1\":\"countyPlacer\",\"2\":\"6.643008e+02\",\"3\":\"8.849706944\",\"4\":\"75.0647210\",\"5\":\"1.330324e-227\"},{\"1\":\"countyRiverside\",\"2\":\"6.343231e+02\",\"3\":\"10.774540113\",\"4\":\"58.8724045\",\"5\":\"3.127789e-191\"},{\"1\":\"countySacramento\",\"2\":\"6.334539e+02\",\"3\":\"9.781729729\",\"4\":\"64.7588871\",\"5\":\"2.494396e-205\"},{\"1\":\"countySan Benito\",\"2\":\"6.444032e+02\",\"3\":\"11.932303812\",\"4\":\"54.0049299\",\"5\":\"1.095166e-178\"},{\"1\":\"countySan Bernardino\",\"2\":\"6.436771e+02\",\"3\":\"8.965825736\",\"4\":\"71.7922887\",\"5\":\"7.855231e-221\"},{\"1\":\"countySan Diego\",\"2\":\"6.545434e+02\",\"3\":\"8.725598285\",\"4\":\"75.0141591\",\"5\":\"1.685011e-227\"},{\"1\":\"countySan Joaquin\",\"2\":\"6.386986e+02\",\"3\":\"9.721697244\",\"4\":\"65.6982567\",\"5\":\"1.763227e-207\"},{\"1\":\"countySan Luis Obispo\",\"2\":\"6.633578e+02\",\"3\":\"13.527093221\",\"4\":\"49.0391950\",\"5\":\"5.900014e-165\"},{\"1\":\"countySan Mateo\",\"2\":\"6.642881e+02\",\"3\":\"9.292046589\",\"4\":\"71.4899654\",\"5\":\"3.421069e-220\"},{\"1\":\"countySanta Barbara\",\"2\":\"6.617452e+02\",\"3\":\"9.201942411\",\"4\":\"71.9136463\",\"5\":\"4.358199e-221\"},{\"1\":\"countySanta Clara\",\"2\":\"6.603073e+02\",\"3\":\"8.959991540\",\"4\":\"73.6950773\",\"5\":\"8.434653e-225\"},{\"1\":\"countySanta Cruz\",\"2\":\"6.717539e+02\",\"3\":\"10.587800247\",\"4\":\"63.4460315\",\"5\":\"2.797908e-202\"},{\"1\":\"countyShasta\",\"2\":\"6.551338e+02\",\"3\":\"9.228176945\",\"4\":\"70.9927685\",\"5\":\"3.891805e-219\"},{\"1\":\"countySiskiyou\",\"2\":\"6.477677e+02\",\"3\":\"10.647405655\",\"4\":\"60.8380774\",\"5\":\"4.610118e-196\"},{\"1\":\"countySonoma\",\"2\":\"6.624791e+02\",\"3\":\"8.875794553\",\"4\":\"74.6388548\",\"5\":\"9.781441e-227\"},{\"1\":\"countyStanislaus\",\"2\":\"6.526065e+02\",\"3\":\"9.371688301\",\"4\":\"69.6359580\",\"5\":\"3.196037e-216\"},{\"1\":\"countySutter\",\"2\":\"6.503123e+02\",\"3\":\"9.426568754\",\"4\":\"68.9871742\",\"5\":\"8.231353e-215\"},{\"1\":\"countyTehama\",\"2\":\"6.486154e+02\",\"3\":\"9.305875519\",\"4\":\"69.6995579\",\"5\":\"2.327624e-216\"},{\"1\":\"countyTrinity\",\"2\":\"6.711595e+02\",\"3\":\"14.187466209\",\"4\":\"47.3065090\",\"5\":\"6.375503e-160\"},{\"1\":\"countyTulare\",\"2\":\"6.328411e+02\",\"3\":\"7.876885616\",\"4\":\"80.3415318\",\"5\":\"5.400340e-238\"},{\"1\":\"countyTuolumne\",\"2\":\"6.534566e+02\",\"3\":\"10.309756625\",\"4\":\"63.3823494\",\"5\":\"3.945513e-202\"},{\"1\":\"countyVentura\",\"2\":\"6.413824e+02\",\"3\":\"9.060707370\",\"4\":\"70.7872271\",\"5\":\"1.067978e-218\"},{\"1\":\"countyYuba\",\"2\":\"6.593117e+02\",\"3\":\"13.799521373\",\"4\":\"47.7778684\",\"5\":\"2.643353e-161\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe coefficient for Alameda county is the greatest out of all the counties, which is why we got all the intercept values as negative in the earlier case. Also, the p-value associated with expenditure (p = 0.54) is greater than 0.05 suggesting that expenditure does not explain the variance seen in the average reading scores.\n\n### Adding a random intercept\n\nWhat if we only want to see how expenditure affects the reading score without the county differences? Let us build a linear mixed effects model with `county` as the 'random effect' and 'expenditure' as the 'fixed effect'. To build a linear mixed effects model we use the function `lmer()` from the `{lme4}` package in R.\n\nThe syntax for building a linear mixed effects model is very similar to the syntax we used while using the `lm()` and `glm()` functions. Here we are considering `county` as a random effect, moreover, the `county` variable is categorical and therefore, we are essentially considering `county` as a random intercept. \n\nThe notation for specifying random effect within the model formula is `(1 | county)`. If we do not specify a random effect term in the model formula, the `lmer()` function won't run. Without further ado, let's see it in action.\n\nThe `tidy()` function from the `{broom}` package in R only work for models built using `lm()` and `glm()`. To extend its usage to mixed effects models, we have to install an additional package called `{broom.mixed}`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(lme4)) install.packages('lme4')\nif (!require(broom.mixed)) install.packages('broom.mixed')\nlibrary(lme4)\nlibrary(broom.mixed)\nlibrary(AER)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + (1 | county), data = CASchools)\n\n# Extracting coefficients from the model\ntidy(model_lmer)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"effect\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"group\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"term\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"fixed\",\"2\":\"NA\",\"3\":\"(Intercept)\",\"4\":\"6.454923e+02\",\"5\":\"7.802918630\",\"6\":\"82.724468\"},{\"1\":\"fixed\",\"2\":\"NA\",\"3\":\"expenditure\",\"4\":\"1.954755e-03\",\"5\":\"0.001418332\",\"6\":\"1.378207\"},{\"1\":\"ran_pars\",\"2\":\"county\",\"3\":\"sd__(Intercept)\",\"4\":\"1.176853e+01\",\"5\":\"NA\",\"6\":\"NA\"},{\"1\":\"ran_pars\",\"2\":\"Residual\",\"3\":\"sd__Observation\",\"4\":\"1.592921e+01\",\"5\":\"NA\",\"6\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIf we look at the slope for expenditure, it is greater than the slope value we got from the linear model but still is almost zero. The standard error for the estimated slope is also less as compared to the earlier built models. But there is a strong role of counties on the average reading score of students. How did I know that? Let us first understand the summary of the linear mixed effects model using the `summary()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_lmer)\n```\n:::\n\n\n![Summary of the linear mixed effects model](images/lmer_summary.png)\n\n1.    In section 1, we can see the model formula that we used to model the data. It also tells us that the model has been fitted by REML, which stands for restricted maximum likelihood method, the method by which lmer models fit the data. \n\n2.    In section 2, there is a value denoting the REML criterion at convergence. I don't know exactly what this is, so if I learn more about it and understand it, then I will update this text. From what I read so far, I learned that this value can be a helpful model diagnostic if our model is not 'converging'. \n\n3.    Section 3 outputs the quantile, min-max and median values of the residual distances of the model.\n\n4.    In section 4, the variance and the standard deviation of both the random intercept variable (county) and the residual (as explained by expenditure) are given. You can see that the variance of counties is more than half the variance of the residual. This variance value is meant to capture all the influences of counties on the average reading score. If we estimate the percentage of variance county contributes as compared to the total variance, then we have;\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounty_variance = 138.5\nresidual_variance = 253.7\ntotal_variance = county_variance + residual_variance\n\n# Calculating the percentage of variance of county to the total variance\ncounty_variance / total_variance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3531362\n```\n:::\n:::\n\n\nSo the differences between counties explain ~35% of the variance that’s “leftover” after the variance explained by our fixed effects (which is expenditure here). If we had county variance as 0, then the percentage of the variance of counties to the total variance would be 0, which suggests that county is truly a random variable which does not explain the variance seen in the average reading scores.\n\n5.    In section 5, we have the coefficient estimates of the fixed effect variable, something which we have seen extensively in the previous tutorials. You can see that the slope of expenditure (0.001955) is close to zero which indicates that expenditure does not explain the differences seen in the average reading score. We saw the same case when we built a linear model using the same dataset.\n\n6.    In section 6, intercept and expenditure coefficients correlate -0.966. This is another value which I am not sure what it means. From what I read, it tells us that if we were to repeat the analysis using a newly sampled dataset, then with newly estimated coefficients of the fixed effect variable, the correlation value tells us how many of those fixed effect coefficients might be associated. You can read more about it [here](https://data.library.virginia.edu/correlation-of-fixed-effects-in-lme4/).\n\nNow that we got a sense of the model summary of a linear mixed effects model, let us see some more functions in R that would be useful for extracting information from the model.\n\n*   To extract the coefficients of the fixed effect variables, use the `fixef()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extracting the coefficients of the fixed effects\nfixef(model_lmer)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept)  expenditure \n6.454923e+02 1.954755e-03 \n```\n:::\n:::\n\n\n*   To extract the coefficients of the random effect variables, use the `ranef()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extracting the coefficients of the fixed effects\nranef(model_lmer)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$county\n                 (Intercept)\nAlameda          11.87352086\nButte            -7.99357120\nCalaveras         2.53892633\nContra Costa     15.33621739\nEl Dorado        10.40224040\nFresno          -17.67664299\nGlenn             6.54693608\nHumboldt          7.30873017\nImperial        -13.90694256\nInyo              2.52932318\nKern            -16.86794250\nKings            -6.14912869\nLake             -7.25773124\nLassen            6.16396434\nLos Angeles      -9.68442015\nMadera           -2.26427074\nMarin            22.22849626\nMendocino        -5.18932165\nMerced          -17.55856455\nMonterey        -13.20359371\nNevada           10.83326539\nOrange           -2.23662764\nPlacer           11.61203226\nRiverside       -11.18209338\nSacramento      -13.86645226\nSan Benito       -4.01536933\nSan Bernardino   -5.97196372\nSan Diego         3.11246174\nSan Joaquin      -9.12283927\nSan Luis Obispo   6.55996266\nSan Mateo        11.56548692\nSanta Barbara     9.16868646\nSanta Clara       8.23860811\nSanta Cruz       15.92725798\nShasta            3.42269880\nSiskiyou         -3.53860484\nSonoma           10.40368948\nStanislaus        1.60937097\nSutter           -0.00741143\nTehama           -1.72590741\nTrinity          10.21145799\nTulare          -16.47382765\nTuolumne          1.76305887\nVentura          -7.73323819\nYuba              4.27007248\n\nwith conditional variances for \"county\" \n```\n:::\n:::\n\n\n*   To calculate the confidence intervals of the fixed effect variables, use the `confint()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculating the confidence intervals of the fixed effects\nconfint(model_lmer)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    2.5 %       97.5 %\n.sig01       8.886716e+00 1.526132e+01\n.sigma       1.483855e+01 1.711469e+01\n(Intercept)  6.298888e+02 6.608656e+02\nexpenditure -8.340782e-04 4.796441e-03\n```\n:::\n:::\n\n\nBy default the `confint()` function calculates the confidence intervals at 95% level. The displayed result from the function is symmetric over the 95% level. The interpretation of 95% CI for expenditure, in this case, would be; that if we were to repeat the experiment 100 times, then, the 95 of those mean values of the slope would fall between $-0.000834$ and $0.004796$. We have a rather wide confidence interval which includes both a negative and a positive limit which shows that we cannot say whether expenditure decrease or increase the average reading scores.\n\n*   We can also use the `tidy()` function by loading both the `{broom}` and `{broom.mixed}` packages to display the estimates and the confidence intervals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nlibrary(broom.mixed)\n\n# Calculating the estimates and the confidence intervals of the model\ntidy(model_lmer, conf.int = T)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"effect\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"group\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"term\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"fixed\",\"2\":\"NA\",\"3\":\"(Intercept)\",\"4\":\"6.454923e+02\",\"5\":\"7.802918630\",\"6\":\"82.724468\",\"7\":\"6.301989e+02\",\"8\":\"6.607857e+02\"},{\"1\":\"fixed\",\"2\":\"NA\",\"3\":\"expenditure\",\"4\":\"1.954755e-03\",\"5\":\"0.001418332\",\"6\":\"1.378207\",\"7\":\"-8.251245e-04\",\"8\":\"4.734635e-03\"},{\"1\":\"ran_pars\",\"2\":\"county\",\"3\":\"sd__(Intercept)\",\"4\":\"1.176853e+01\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"NA\",\"8\":\"NA\"},{\"1\":\"ran_pars\",\"2\":\"Residual\",\"3\":\"sd__Observation\",\"4\":\"1.592921e+01\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"NA\",\"8\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nYou can see that the random effect variables do not have standard error values. If we compare the model summary between the linear model and the linear mixed effects model we built, we can also see that p-values are not reported for the linear mixed effects model. The author of the `{lme4}` package, Dr. Doug Bates views random effects as latent variables which do not have standard deviations and thus standard errors or p-values are [not calculated](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html) for them. In addition to this, it is an open research question on how to calculate the p-values for random effects in a mixed-effects model. But using the `{lmerTest}` package in R we can perform ad-hoc analyses to report p-values for the fixed effect variables. We will see how to do this further down the section.\n\n### Adding a random slope\n\nSo far we have seen how to input random intercepts, now we will see how to input random slopes. The default syntax for random effect in R is `(continuous_predictor | random_effect_group)`. Thus a random slope is calculated, it also estimates a random effect intercept.\n\nIn the `CASchools` dataset, we looked at whether the average reading score is predicted by the expenditure by treating counties as the random intercept group. Now in our datasets, we also have data on the number of students and this could be different for different counties and can affect the average reading score. So this time let us build a model by treating `students` as the random effect variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(broom.mixed)\nlibrary(AER)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model using random slope and random intercept\nmodel_lmer2 <- lmer(read ~ expenditure + (students | county), data = CASchools)\n\n# Extracting coefficients from the model\nsummary(model_lmer2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: read ~ expenditure + (students | county)\n   Data: CASchools\n\nREML criterion at convergence: 3593.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.67995 -0.64452  0.00953  0.66738  2.52830 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev.  Corr \n county   (Intercept) 3.475e+02 18.642621      \n          students    1.354e-06  0.001164 -0.95\n Residual             2.342e+02 15.303481      \nNumber of obs: 420, groups:  county, 45\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept) 6.467e+02  7.706e+00  83.918\nexpenditure 6.341e-04  1.413e-03   0.449\n\nCorrelation of Fixed Effects:\n            (Intr)\nexpenditure -0.958\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n:::\n:::\n\n\nThe variance of students is very less and therefore might not be affecting the scores that much. Also, note that we got an error message in the output saying `boundary (singular) fit`. This generally indicates that the estimate for the random effect variable that we used is very small. In our, it means that the random effect slopes of students are very small which we can see using the `ranef()` function. So we can remove `students` from our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nranef(model_lmer2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$county\n                (Intercept)      students\nAlameda          24.4785039 -1.441929e-03\nButte            -3.4180179  1.775858e-04\nCalaveras         7.9826401 -4.681762e-04\nContra Costa     25.4891245 -1.424787e-03\nEl Dorado        17.9072929 -1.012206e-03\nFresno          -14.0623193  8.308013e-04\nGlenn            12.4209156 -7.319719e-04\nHumboldt         13.8328480 -8.081011e-04\nImperial        -12.2869252  7.016373e-04\nInyo              7.7750632 -4.532749e-04\nKern            -12.5277014  4.649777e-04\nKings            -1.0528421  1.423524e-05\nLake             -5.6736709  3.339620e-04\nLassen           12.5326580 -7.406065e-04\nLos Angeles      -2.0794607 -2.426704e-04\nMadera            2.8489240 -1.656228e-04\nMarin            34.7443486 -2.051422e-03\nMendocino        -4.6943124  2.762367e-04\nMerced          -14.2569750  7.113461e-04\nMonterey         -8.4968704  2.996187e-04\nNevada           18.6703498 -1.085232e-03\nOrange            8.6097926 -6.360256e-04\nPlacer           19.4641692 -1.099682e-03\nRiverside       -10.6949200  6.195711e-04\nSacramento      -12.6097930  7.103399e-04\nSan Benito        0.1126231 -3.550850e-05\nSan Bernardino    2.9274439 -3.988533e-04\nSan Diego        14.1621214 -8.451098e-04\nSan Joaquin      -6.2010253  3.738934e-04\nSan Luis Obispo  13.5823846 -7.993061e-04\nSan Mateo        24.7224461 -1.651387e-03\nSanta Barbara    20.4963141 -1.417024e-03\nSanta Clara      22.7310750 -1.376439e-03\nSanta Cruz       26.5648214 -1.605235e-03\nShasta           10.2142367 -6.282100e-04\nSiskiyou          2.5622804 -1.403162e-04\nSonoma           18.0499478 -1.078872e-03\nStanislaus        9.0155040 -5.928210e-04\nSutter            4.5333780 -2.714554e-04\nTehama            3.3731884 -2.120293e-04\nTrinity          19.7049606 -1.160587e-03\nTulare          -12.6199437  7.048954e-04\nTuolumne          7.6541244 -4.484524e-04\nVentura          -1.4092318 -1.002546e-04\nYuba             10.9917466 -6.477161e-04\n\nwith conditional variances for \"county\" \n```\n:::\n:::\n\n\n### Adding a non-correlated random effects\n\nPlease also note that in the model summary given above, a correlation value (-0.95) is given for the correlation between `students` and `county`. If we don't want to specify any correlation between the random effects then instead of using `|` we use `||` to specify no correlation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(broom.mixed)\nlibrary(AER)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model (no correlation between random effects)\nmodel_lmer3 <- lmer(read ~ expenditure + (students || county), data = CASchools)\n\n# Extracting coefficients from the model\nsummary(model_lmer3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: read ~ expenditure + ((1 | county) + (0 + students | county))\n   Data: CASchools\n\nREML criterion at convergence: 3592.6\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.73060 -0.62225  0.01112  0.63847  2.40069 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev.\n county   (Intercept) 1.311e+02 11.44819\n county.1 students    2.434e-06  0.00156\n Residual             2.400e+02 15.49234\nNumber of obs: 420, groups:  county, 45\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept) 6.503e+02  7.738e+00  84.039\nexpenditure 1.321e-03  1.401e-03   0.943\n\nCorrelation of Fixed Effects:\n            (Intr)\nexpenditure -0.966\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 8.66886 (tol = 0.002, component 1)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\nModel is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n```\n:::\n:::\n\n\nThe model outputs a lot of error values because `students` and `county` is correlated as seen before.\n\n### Adding the same variable as both fixed and random effect\n\nSometimes we can have a model with both the fixed effect and the random effect as the same variable. Suppose we are interested in seeing the average effect of expenditure on the average reading scores across counties. In that case, we use `expenditure` both as a fixed effect and as a random effect. Before using `expenditure` in the model formula, it is better to use the `scale()` function to rescale the data values for better numerical stability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(broom.mixed)\nlibrary(AER)\n\ndata(\"CASchools\")\n\n# Rescaling expenditure values\nCASchools_scaled <- CASchools\nCASchools_scaled$expenditure_scaled <- scale(CASchools_scaled$expenditure)\n\n# Building a linear mixed effects model (same fixed and random effect)\nmodel_lmer4 <- lmer(read ~ expenditure + (expenditure | county), data = CASchools)\n\n# Extracting coefficients from the model\nsummary(model_lmer4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: read ~ expenditure + (expenditure | county)\n   Data: CASchools\n\nREML criterion at convergence: 3563.6\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.63568 -0.62932  0.02378  0.64384  2.60189 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev.  Corr \n county   (Intercept) 6.566e+02 25.623717      \n          expenditure 3.880e-05  0.006229 -0.94\n Residual             2.254e+02 15.014211      \nNumber of obs: 420, groups:  county, 45\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept) 6.534e+02  9.100e+00  71.801\nexpenditure 3.237e-04  1.828e-03   0.177\n\nCorrelation of Fixed Effects:\n            (Intr)\nexpenditure -0.976\noptimizer (nloptwrap) convergence code: 0 (OK)\nunable to evaluate scaled gradient\nModel failed to converge: degenerate  Hessian with 1 negative eigenvalues\n```\n:::\n:::\n\n\nThe table below shows all the different types of random effect syntaxes we can use in the `lmer()` function.\n\n| Random effect syntax | What it means |\n|---|---|\n| (1 \\| group) | Random intercept with fixed mean |\n| (1 \\| g1/g2) | Intercepts vary among g1 and g2 within g1 |\n| (1 \\| g1) + (1 \\| g2) | Random intercepts for 2 variables |\n| x + (x \\| g) | Correlated random slope and intercept |\n| x + (x \\|\\| g) | Uncorrelated random slope and intercept |\n\n: Different random effect syntaxes used in the `{lme4}` package\n\n## Plotting lmer models\n\nEarlier we had functions like `fmodel()` from the `{statisticalModeling}` package and arguments like `geom_smooth()` or `stat_smooth()` from the `{ggplot2}` package in R to help us plot linear models and generalized linear models. Thanks to the `{ggeffects}` package in R, we have an easy of plotting our lmer models. But first, let us see how we got it with the `{ggplot2}` package in R.\n\nWe will have to do some manual tidying and wrangling of our model object to extract values which we need to plot using the `{ggplot2}` package.\n\nTo plot the trend line, we can use the `predict()` function to predict values using the training dataset itself and save those predicted values into a new column in the dataset. Then plot the trend lines them using those predicted values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndata(\"CASchools\")\n\n# Building a linear model\nmodel_lm <- lm(read ~ expenditure + county, data = CASchools)\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + (1 | county), data = CASchools)\n\n# Saving predicted values for each model\ndata <- CASchools %>% mutate(predicted_lm = predict(model_lm),\n                             predicted_lmer = predict(model_lmer))\n\n# Plotting the predicted values as lines\nggplot(data, aes(x = expenditure, y = read, color = county)) +\n  geom_point() +\n  geom_line(aes(x = expenditure, y = predicted_lm)) +\n  geom_line(aes(x = expenditure, y = predicted_lmer), linetype = 'dashed') +\n  labs(title = \"Linear models vs Linear mixed effects model\",\n       x = \"Expenditure per student (in dollars)\",\n       y = \"Average reading score\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nWe have 54 different counties which make the plot somewhat overwhelming.\n\nWe can also plot the predicted values as data points in the plot. Let us build another model without any groups using the same dataset. We will use the number of teachers in the school (`teachers`) as a random effect instead of the counties.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndata(\"CASchools\")\n\n# Building a linear model\nmodel_lm <- lm(read ~ expenditure + teachers, data = CASchools)\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + (1 | teachers), data = CASchools)\n\n# Saving predicted values for each model\ndata <- CASchools %>% mutate(predicted_lm = predict(model_lm),\n                             predicted_lmer = predict(model_lmer))\n\n# Plotting the predicted values as points\nggplot(data, aes(x = expenditure, y = read)) +\n  geom_point() +\n  geom_point(data = data,\n             aes(x = expenditure, y = predicted_lm),\n             color = \"red\", alpha = 0.5) +\n  geom_point(data = data,\n             aes(x = expenditure, y = predicted_lmer),\n             color = 'blue', alpha = 0.5) +\n  labs(title = \"Linear models vs Linear mixed effects model\",\n       x = \"Expenditure per student (in dollars)\",\n       y = \"Average reading score\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nWith the `{ggeffects}` package, plotting a lmer model is as easy as two lines of code. Since we have 54 counties, I am not plotting them via counties, so it is not included in the `terms = \"c()\"` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(ggeffects)) install.packages('ggeffects')\nlibrary(lme4)\nlibrary(AER)\nlibrary(ggeffects)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + (1 | county), data = CASchools)\n\n# Predicting values\nmodel_lmer_predict <- ggpredict(model_lmer, terms = c(\"expenditure\"))\n\n# Plotting the model\nplot(model_lmer_predict)\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## Plotting the residuals\n\nWe can use the base `plot()` function to plot the residuals of the models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndata(\"CASchools\")\n\n# Building a linear model\nmodel_lm <- lm(read ~ expenditure + county, data = CASchools)\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + (1 | county), data = CASchools)\n\n# Plotting the linear model diagnostics\npar(mfrow=c(2,2))\nplot(model_lm)\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plotting the linear mixed effects model diagnostics (just the residuals actually)\nplot(model_lmer)\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n\n## Plotting the cofidence intervals\n\nWe can also plot the confidence intervals of the fixed effect variables using the `ggplot()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(ggplot2)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + (1 | county), data = CASchools)\n\n# Extracting the coefficients\nmodel_lmer_coef <- tidy(model_lmer, conf.int = T)\nmodel_lmer_coef1 <- model_lmer_coef %>% \n  filter(effect == \"fixed\" & term != \"(Intercept)\")\n\n# Plotting the 95% CI\nmodel_lmer_conf <- ggplot(model_lmer_coef1, aes(x = term, y = estimate,\n                             ymin = conf.low, ymax = conf.high)) +\n  geom_hline(yintercept = 0, color = 'red') + \n  geom_point() +\n  geom_linerange() +\n  coord_flip() +\n  labs(title = \"Linear models vs Linear mixed effects model\",\n       x = \"Regression coefficient\",\n       y = \"Coefficient estimate and 95% CI\") +\n  theme_bw()\n\nmodel_lmer_conf\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nLet us try including more fixed effect terms in the model. We will include the number of teachers in the school (`teachers`) and the number of students in the school (`students`) as fixed effects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(ggplot2)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + teachers + students + (1 | county),\n                   data = CASchools)\n\n# Extracting the coefficients\nmodel_lmer_coef <- tidy(model_lmer, conf.int = T)\nmodel_lmer_coef1 <- model_lmer_coef %>% \n  filter(effect == \"fixed\" & term != \"(Intercept)\")\n\n# Plotting the 95% CI\nmodel_lmer_conf <- ggplot(model_lmer_coef1, aes(x = term, y = estimate,\n                             ymin = conf.low, ymax = conf.high)) +\n  geom_hline(yintercept = 0, color = 'red') + \n  geom_point() +\n  geom_linerange() +\n  coord_flip() +\n  labs(title = \"Linear models vs Linear mixed effects model\",\n       x = \"Regression coefficient\",\n       y = \"Coefficient estimate and 95% CI\") +\n  theme_bw()\n\nmodel_lmer_conf\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Null hypothesis testing\n\nAs mentioned earlier, p values are not calculated for fixed terms using the `{lme4}` package for various reasons. So if we have to calculate the p values, we have to use the `{lmerTest}` package in R. By loading the `{lmerTest}` package, the `{lme4}` package is automatically loaded. We don't have to provide any special syntax for calculating the p-values, instead, p-values are automatically calculated when calling the `lmer()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(lmerTest)) install.packages('lmerTest')\nlibrary(lmerTest)\nlibrary(AER)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model\nmodel_lmer <- lmer(read ~ expenditure + teachers + students + (1 | county),\n                   data = CASchools)\n\n# Printing model summary\nsummary(model_lmer)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: read ~ expenditure + teachers + students + (1 | county)\n   Data: CASchools\n\nREML criterion at convergence: 3590.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7343 -0.6384  0.0471  0.6343  2.2823 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n county   (Intercept) 138.6    11.77   \n Residual             239.6    15.48   \nNumber of obs: 420, groups:  county, 45\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept) 652.737953   7.767375 412.474266  84.036   <2e-16 ***\nexpenditure   0.001005   0.001404 410.295073   0.715   0.4749    \nteachers      0.085024   0.058332 391.351530   1.458   0.1458    \nstudents     -0.005188   0.002825 392.820325  -1.836   0.0671 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) expndt techrs\nexpenditure -0.964              \nteachers     0.141 -0.163       \nstudents    -0.152  0.170 -0.997\nfit warnings:\nSome predictor variables are on very different scales: consider rescaling\n```\n:::\n:::\n\n\nFor fixed effects, p-values are calculated to test if the coefficients are significantly different from zero.\n\n## Model comparison using ANOVA\n\nWe can use ANOVA to compare two models to see which one is better. The ANOVA test is called by the function `anova()` and it is used to compare models by comparing the amount of variability explained by each model.\n\nLet us test if the number of teachers significantly affects the average reading score of students across different counties. First, we will build a 'null model' with just `county` as the random effect. Then we will build another model with `teachers` as the fixed effect and the rest the same as the previous model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\n\ndata(\"CASchools\")\n\n# Building a linear mixed effects model with only random effect (null model)\nmodel_lmer_null <- lmer(read ~ (1 | county),\n                   data = CASchools)\n\n# Building a linear mixed effects model with fixed effect\nmodel_lmer_teacher <- lmer(read ~ teachers + (1 | county),\n                   data = CASchools)\n\n# Comparing models using ANOVA\nanova(model_lmer_null, model_lmer_teacher)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"npar\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIC\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"logLik\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviance\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Chisq\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Df\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>Chisq)\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"3\",\"2\":\"3595.339\",\"3\":\"3607.460\",\"4\":\"-1794.670\",\"5\":\"3589.339\",\"6\":\"NA\",\"7\":\"NA\",\"8\":\"NA\",\"_rn_\":\"model_lmer_null\"},{\"1\":\"4\",\"2\":\"3575.732\",\"3\":\"3591.893\",\"4\":\"-1783.866\",\"5\":\"3567.732\",\"6\":\"21.60661\",\"7\":\"1\",\"8\":\"3.346957e-06\",\"_rn_\":\"model_lmer_teacher\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nFrom the ANOVA result, it seems like adding the variable teacher made the model better as it yielded significant p-values.\n\n## Generalized linear mixed effects model\n\nSame way as we made the transition from linear models to generalized linear models, we now transition from linear mixed effects model to generalized mixed effects model. As you might have guessed, we will be dealing with datasets which do not follow the normal distribution and are in the form of a count or binomial type.\n\nWe use the `glmer()` function to build generalized linear mixed effects models (glmer models) and use the `family = \" \"` argument to specify the distribution of residuals of the data. If it's non-normal and is count then we use `family = \"poisson\"` and if it's binomial then we use `family = \"binomial\"`.\n\n### Logistic mixed effects model\n\nFor this exercise, we will be using the `CreditCard` dataset from the `{AER}` package in R. The dataset contains the credit history of a sample of applicants for a type of credit card. We will be building a glmer model to predict the success of the acceptance of the credit card application (`card`) using yearly income (`income`) as the fixed effect and the house ownership status (`owner`) as the random effect.\n\nLet us first build a plot and visualize the data before building the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(AER)\n\ndata(\"CreditCard\")\n\n# Plotting the data\nggplot(CreditCard, aes(income, card, col = owner)) +\n  geom_jitter(width = 0, height = 0.05) +\n  labs(title = \"Does income affect the success in accepting a credit card application?\",\n       x = \"Yearly income (in USD 10,000)\",\n       y = \"Was the application for a credit card accepted?\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nIt seems like individuals with low yearly income tend to have the most number of credit card application rejections.\n\nNow let us build the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\n\ndata(\"CreditCard\")\n\n# Building a logistic mixed effects model\nmodel_glmer_logistic <- glmer(card ~ income + (1 | owner), family = \"binomial\",\n                           data = CreditCard)\n\n# Printing the summary of the model\nsummary(model_glmer_logistic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: card ~ income + (1 | owner)\n   Data: CreditCard\n\n     AIC      BIC   logLik deviance df.resid \n  1384.1   1399.6   -689.0   1378.1     1316 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2271  0.3708  0.4626  0.6115  0.6626 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n owner  (Intercept) 0.09638  0.3105  \nNumber of obs: 1319, groups:  owner, 2\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.99357    0.27913   3.560 0.000371 ***\nincome       0.09610    0.04779   2.011 0.044338 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr)\nincome -0.564\n```\n:::\n:::\n\n\nFrom a quick look, it seems like income does significantly explain the variance seen in the success of accepting a credit card application.\n\nWe learned from logistic GLMs that it's easier to interpret the coefficients as odds ratio by exponentiating them. The same principle follows here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(AER)\n\ndata(\"CreditCard\")\n\n# Building a logistic mixed effects model\nmodel_glmer_logistic <- glmer(card ~ income + (1 | owner), family = \"binomial\",\n                           data = CreditCard)\n\n# Extracting the odds ratios\ntidy(model_glmer_logistic, exponentiate = T)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"effect\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"group\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"term\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"fixed\",\"2\":\"NA\",\"3\":\"(Intercept)\",\"4\":\"2.7008586\",\"5\":\"0.75388048\",\"6\":\"3.559571\",\"7\":\"0.0003714605\"},{\"1\":\"fixed\",\"2\":\"NA\",\"3\":\"income\",\"4\":\"1.1008665\",\"5\":\"0.05260904\",\"6\":\"2.010882\",\"7\":\"0.0443378740\"},{\"1\":\"ran_pars\",\"2\":\"owner\",\"3\":\"sd__(Intercept)\",\"4\":\"0.3104551\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWe can see that the odds ratio for income is very close to 1, which is why the p-value associated with income is close to the level of significance of 0.05. So there is a weak effect on income in deciding the success of accepting credit card applications. There might be some other variables that we are missing to incorporate into the model.\n\n### Plotting a logistic mixed effects model\n\nAs we saw in the case with the linear mixed effects model, we will be using the `{ggeffects}` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(ggeffects)\nlibrary(AER)\n\ndata(\"CreditCard\")\n\n# Building a logistic mixed effects model\nmodel_glmer_logistic <- glmer(card ~ income + (1 | owner), family = \"binomial\",\n                           data = CreditCard)\n\n# Predicting values\nmodel_glmer_logistic_predict <- ggpredict(model_glmer_logistic, \"income\")\n\n# Plotting the model\nplot(model_glmer_logistic_predict)\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n### Poisson mixed effects model\n\nFor this exercise, we will be using the `RecreationDemand` dataset from the `{AER}` package in R. The data is on the number of recreational boating trips to Lake Somerville, Texas, in 1980, based on a survey administered to 2,000 registered leisure boat owners in 23 counties in eastern Texas, USA.\n\nWe will be predicting the number of boating trips (`trips`) using the annual household income of the respondent (`income`) as the fixed effect and water-skiing status at the lake (`ski`) as the random effect.\n\nLet us first build a plot and visualize the data before building the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(AER)\n\ndata(\"RecreationDemand\")\n\n# Plotting the data\nggplot(RecreationDemand, aes(income, trips, col = ski)) + \n  geom_jitter(width = 0.05, height = 0) +\n  labs(title = \"Does income affect the number of recreational boating trips?\",\n       x = \"Annual household income of the respondent (in 1,000 USD)\",\n       y = \"Number of recreational boating trips\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nThe graph tells us that most boating trips are made by people with less annual household income. Please note that there are many zeros in the dataset, essentially we have a zero-inflated dataset. But for now, we will ignore it. Skiing status doesn't seem to affect the number of boating trips made.\n\nNow let us build the model and see.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(AER)\n\ndata(\"RecreationDemand\")\n\n# Building a poisson mixed effects model\nmodel_glmer_poisson <- glmer(trips ~ income + (1 | ski), family = \"poisson\",\n                           data = RecreationDemand)\n\n# Printing the summary of the model\nsummary(model_glmer_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: trips ~ income + (1 | ski)\n   Data: RecreationDemand\n\n     AIC      BIC   logLik deviance df.resid \n  5454.7   5468.2  -2724.4   5448.7      656 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-2.192 -1.506 -1.291 -0.242 56.932 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ski    (Intercept) 0.09025  0.3004  \nNumber of obs: 659, groups:  ski, 2\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.42434    0.22221   6.410 1.46e-10 ***\nincome      -0.15402    0.01674  -9.199  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr)\nincome -0.269\n```\n:::\n:::\n\n\nSeems like income has a significant negative impact on the number of boating trips as seen earlier in the graph.\n\n### Plotting a Poisson mixed effects model\n\nAgain we will be using the `{ggeffects}` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(ggeffects)\nlibrary(AER)\n\ndata(\"RecreationDemand\")\n\n# Building a poisson mixed effects model\nmodel_glmer_poisson <- glmer(trips ~ income + (1 | ski), family = \"poisson\",\n                           data = RecreationDemand)\n\n# Predicting values\nmodel_glmer_poisson_predict <- ggpredict(model_glmer_poisson,\n                                         terms = c(\"income\", \"ski\"))\n\n# Plotting the model\nplot(model_glmer_poisson_predict)\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n## Repeated measures data\n\nIf we measure variables across time for the same set of observations then essentially we have repeated measures data. Repeated measures are a special case of a mixed-effects model. Examples of repeated measures include; tracking test scores of students across an academic year, measuring drug effects on patients over time, measuring the growth of bacteria over time, measuring flower phenology over different seasons etc.\n\nWe will be using the `sleep` dataset from the `{datasets}` package in R. The data show the effect of two soporific drugs (increase in hours of sleep compared to control) on 10 patients. In this case, we are measuring sleep difference in hours across time (`extra`) for two groups (`group`), essentially repeated measured data.\n\nFirst, let us visualize the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(datasets)) install.packages('datasets')\nlibrary(datasets)\nlibrary(ggplot2)\n\ndata(\"sleep\")\n\n# Plotting the graph\nggplot(sleep, aes(group, extra, group = ID)) + geom_line() +\n  labs(title = \"Effect of two soporific drugs on sleep in 10 patients\",\n       x = \"Drug group\",\n       y = \"Increase in hours of sleep compared to control\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](glmer_stat_model_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nThe graph shows that drug 2 as compared to drug 1 increases the amount of sleep in hours when compared to control. Now let us see if this difference is statistically significant.\n\nIn introductory statistic classes, we would have learned that to compare means across time for this 'paired' dataset, we can use a paired t-test. Performing a t-test in R is through the `t.test()` function. If we use `t.test(paired = T)` then essentially we are doing a paired t.test. Let us do a paired t-test on the above-mentioned dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(datasets)\n\ndata(\"sleep\")\n\n# Performing a paired t.test\nt.test(extra ~ group, paired = T, data = sleep)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  extra by group\nt = -4.0621, df = 9, p-value = 0.002833\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.4598858 -0.7001142\nsample estimates:\nmean difference \n          -1.58 \n```\n:::\n:::\n\n\nThe t-test results suggest a significant difference between the mean of the sleep differences and the difference between the mean of the sleep difference between the two groups is -1.58. In other words, group 2 has a 1.58 value greater mean as compared to group 1. \n\nNow let us run a linear mixed effects model with `extra` as the response variable, `group` as the fixed effect and the `ID` as the random effect. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(datasets)\n\ndata(\"sleep\")\n\n# Building a linear mixed effect model\nsummary(lmer(extra ~ group + (1 | ID), data = sleep))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: extra ~ group + (1 | ID)\n   Data: sleep\n\nREML criterion at convergence: 70\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.63372 -0.34157  0.03346  0.31511  1.83859 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 2.8483   1.6877  \n Residual             0.7564   0.8697  \nNumber of obs: 20, groups:  ID, 10\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)   \n(Intercept)   0.7500     0.6004 11.0814   1.249  0.23735   \ngroup2        1.5800     0.3890  9.0000   4.062  0.00283 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr)\ngroup2 -0.324\n```\n:::\n:::\n\n\nIf we closely compare the paired t-test result and the summary of the linear mixed effect model, we can notice some similarities.\n\n1.    The test statistic t-value is the same in both the results if we ignore the sign (4.062).\n2.    The p-value is the same (0.00283)\n3.    The coefficient for the group2 is the same as the mean difference denoted in the paired t-test result after ignoring the sign (1.5800).\n\nPaired t-test is a special case of repeated measures ANOVA. If we have only two dependent groups and if it's normally distributed, then we use the paired t-test to compare their means. If we have more than 2 dependent groups, then we go repeated measures ANOVA. On the other hand, repeated measures ANOVA is a special case of the mixed effects model.\n\nSo to compare the means for paired data, we can go for two different statistical approaches; \n\n1.    Regression analysis\n2.    ANOVA type approach\n\nWe already saw the regression analysis approach which is what we did earlier. Here, we build a linear mixed model and then examine if the drug group coefficient differs greatly from zero. In our case, the coefficient for group2 is 1.58 and is significantly greater than 0. So we can directly see that group2 significantly affects extra hours of sleep as compared to group1, without the need for any post hoc test which is needed if we are running an ANOVA.\n\nSo the null and alternate hypotheses for the *regression analysis* of our data would be;\n\n*   $H_0$ = Drug group coefficient is zero\n*   $H_a$ = Drug group coefficient is not zero\n\nIn the second approach, we examine if the drug group covariate explains a significant amount of variability within the model. There will be no effect on the drug group if the amount of sleep the study participants get in both groups is similar. ANOVA will only tell that there is a significant difference between some groups in the model, to see which groups differ from each other, we have to go for a post hoc test.\n\nSo the null and alternate hypothesis for the *ANOVA type approach* for our data would be;\n\n*   $H_0$ = Drug group does not significantly explain the differences in extra sleep hours\n*   $H_a$ = Drug group significantly explain the differences in extra sleep hours\n\nGoing forward with the ANOVA type approach can be as easy as using the function `anova()` by giving the model as the input.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(datasets)\n\ndata(\"sleep\")\n\n# Building a linear mixed effects model\nsleep_model <- lmer(extra ~ group + (1 | ID), data = sleep)\n\n# Performing a ANOVA\nanova(sleep_model)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Sum Sq\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Mean Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"NumDF\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"DenDF\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"12.482\",\"2\":\"12.482\",\"3\":\"1\",\"4\":\"9\",\"5\":\"16.50088\",\"6\":\"0.00283289\",\"_rn_\":\"group\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAs we have seen earlier, the drug group does significantly explain the differences in extra sleep hours of the patients. We can also see that the p-values calculated are identical to that of the model summary we saw before.\n\n## Fixed effect models (lm and glm) vs Mixed effects models (lmer and glmer)\n\nWe have reached the final level of the tutorial. Here we will compare the fixed effects models and mixed effects models and get an overall picture of the differences between them.\n\n| Fixed effects model | Mixed effects model |\n|---|---|\n| Generally more impacted by outliers | More robust to outliers |\n| Use `lm()` or `glm()` in base R | Use `lmer()` or `glmer()` from `{lme4}` package in R |\n| Easier to explain | Computationally harder to fit |\n| Easier to build | More robust to small group sizes |\n|  | Models nested distributions |\n\n: Review of fixed effects model and mixed effects model\n\n## Conlusion\n\nFinally, we have completed the most needed things in statistical modelling that concerns a PhD student, especially if that student is studying Ecology. In summary, we learned the following things;\n\n1.    What is a hierarchical model/mixed effects model?\n\n2.    What are fixed effects and random effects?\n\n3.    Building a linear mixed effects model\n\n4.    Adding random intercept group and random effect slope\n\n5.    Random effect syntaxes used in `{lme4}` packages\n\n6.    Plotting linear mixed effects model, the residuals and the confidence intervals\n\n7.    Model comparison using ANOVA\n\n8.    Building generalized mixed effects models: *Logistic* and *Poisson*\n\n9.    Plotting generalized mixed effects models\n\n10.   Repeated measures data\n\n11.   Paired t-test and repeated measures ANOVA is a special case of mixed effects model\n\nNow where to go from here? Normally, whatever is covered till now will be enough for most purposes as a student of science. Now if you the reader is still interested in learning more, then I welcome you to learn 'Non-linear Modelling in R with Generalized Additive Models (GAM)' which would raise our modelling repertoire to even higher levels. Congratulations for making it this far, I wish you all the best 👍 \n\n<!-- Do not forget to put flag counter -->\n<a hidden href=\"https://info.flagcounter.com/ynrK\"><img src=\"https://s11.flagcounter.com/count2/ynrK/bg_000000/txt_FFFFFF/border_F0F0F0/columns_5/maxflags_25/viewers_0/labels_1/pageviews_1/flags_0/percent_0/\" alt=\"Flag Counter\" border=\"0\"/></a>",
    "supporting": [
      "glmer_stat_model_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}